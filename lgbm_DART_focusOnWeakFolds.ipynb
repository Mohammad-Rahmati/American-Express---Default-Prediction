{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from evaluation_metric import lgb_amex_metric\n",
    "\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "global max_score\n",
    "max_score = 0.780\n",
    "\n",
    "def save_model():\n",
    "    def callback(env):\n",
    "        global max_score\n",
    "        iteration = env.iteration\n",
    "        score = env.evaluation_result_list[0][2]\n",
    "        if iteration % 500 == 0:\n",
    "            print('iteration {}, score= {:.05f}'.format(iteration,score))\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            path = 'Models/'\n",
    "            for fname in os.listdir(path):\n",
    "                if fname.startswith(\"weak_fold\"):\n",
    "                    os.remove(os.path.join(path, fname))\n",
    "\n",
    "            print('High Score: iteration {}, score={:.05f}'.format(iteration, score))\n",
    "            joblib.dump(env.model, 'Models/weak_fold_score_{:.05f}.pkl'.format(score))\n",
    "\n",
    "    callback.order = 0\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indx = pd.read_pickle('Data/weak_fold_indx.pkl')['weak_index'].tolist()\n",
    "train_val = pd.read_parquet('Data/train_all.parquet')\n",
    "train_indx = set(train_val.index).difference(set(val_indx))\n",
    "train = train_val.loc[train_indx]\n",
    "val = train_val.loc[val_indx]\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "for cat_col in cat_features:\n",
    "    encoder = LabelEncoder()\n",
    "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "    val[cat_col] = encoder.transform(val[cat_col])\n",
    "    \n",
    "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "num_cols = [col for col in num_cols if 'last' in col]\n",
    "for col in num_cols:\n",
    "    train[col + '_round2'] = train[col].round(2)\n",
    "    val[col + '_round2'] = val[col].round(2)\n",
    "\n",
    "features = [col for col in train.columns if col not in ['target']]\n",
    "\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(lgb_train, lgb_valid, parameters):\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params = parameters,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 15000,\n",
    "        valid_sets = [lgb_valid],\n",
    "        feval = lgb_amex_metric,\n",
    "        callbacks=[save_model()],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': ['binary'],\n",
    "    'metric': ['amex_metric'],\n",
    "    'boosting': ['dart'],\n",
    "    'seed': [42],\n",
    "    'num_leaves': [100],\n",
    "    'learning_rate': [0.01, 0.005],\n",
    "    'drop_rate': [0.01, 0.025, 0.05, 0.1, 0.2],\n",
    "    'feature_fraction': [0.20],\n",
    "    'bagging_freq': [10],\n",
    "    'bagging_fraction': [0.50],\n",
    "    'n_jobs': [-1],\n",
    "    'lambda_l2': [2],\n",
    "    'min_data_in_leaf': [40]\n",
    "    }\n",
    "\n",
    "lgb_train = lgb.Dataset(train[features], train['target'], categorical_feature = cat_features)\n",
    "lgb_valid = lgb.Dataset(val[features], val['target'], categorical_feature = cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid  = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "for run, parameters in enumerate(grid):\n",
    "    print('-'*50)\n",
    "    print(run, len_grid, parameters)\n",
    "    train_and_evaluate(lgb_train, lgb_valid, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rapids-22.06')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "468ef23ed2970eb3eae24d512361eed443dbea3050d88b5fbf8075c8ae4b100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
