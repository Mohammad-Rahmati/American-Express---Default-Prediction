{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metric import lgb_amex_metric, amex_metric\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Output/train_DART_folds.csv', index_col='customer_ID')\n",
    "labels = pd.read_pickle('Data/train_labels.pkl').loc[data.index]\n",
    "columns = data.columns\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mean'] = data[columns].mean(axis=1)\n",
    "data['std'] = data[columns].std(axis=1)\n",
    "data['min'] = data[columns].min(axis=1)\n",
    "data['max'] = data[columns].max(axis=1)\n",
    "data['median'] = data[columns].median(axis=1)\n",
    "data['skew'] = data[columns].skew(axis=1)\n",
    "data['kurtosis'] = data[columns].kurtosis(axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(data, labels)):\n",
    "    \n",
    "    print(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(fold, ave_score):\n",
    "    def callback(env):\n",
    "        iteration = env.iteration\n",
    "        score = env.evaluation_result_list[0][2]\n",
    "        if iteration % 50 == 0:\n",
    "            print('iteration {}, score= {:.05f}, max_score= {:.05f}, ave_score= {:.05f}'.format(iteration,score, score_dict[fold], ave_score))\n",
    "        if score > score_dict[fold]:\n",
    "            score_dict[fold] = score\n",
    "\n",
    "            path = 'Ensemble_DART/'\n",
    "            for fname in os.listdir(path):\n",
    "                if fname.startswith(\"fold_{}_iter\".format(fold)):\n",
    "                    os.remove(os.path.join(path, fname))\n",
    "\n",
    "            print('High Score: iteration {}, score={:.05f}, ave_score={:.05f}'.format(iteration, score, ave_score))\n",
    "            joblib.dump(env.model, path + 'fold_{}_iter_{}_score_{:.05f}.pkl'.format(fold, iteration, score))\n",
    "\n",
    "    callback.order = 0\n",
    "    return callback\n",
    "\n",
    "\n",
    "def train_and_evaluate(data, parameters):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(data, labels)):\n",
    "        \n",
    "        print('')\n",
    "        \n",
    "        x_train, x_val = data.iloc[trn_ind], data.iloc[val_ind]\n",
    "        y_train, y_val = labels.iloc[trn_ind], labels.iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val)\n",
    " \n",
    "        ave_score = amex_metric(y_val['target'], x_val['mean'])\n",
    "        del x_train, x_val, y_train, y_val; gc.collect()\n",
    "        \n",
    "        path = 'Ensemble_DART/'\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params = parameters,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 250,\n",
    "            valid_sets = [lgb_valid],\n",
    "            feval = lgb_amex_metric,\n",
    "            callbacks=[save_model(fold, ave_score)],\n",
    "            # init_model= path + 'cp_{}_model.txt'.format(fold),\n",
    "            )\n",
    "        \n",
    "        for fname in os.listdir(path):\n",
    "            if fname.startswith(\"fold_{}_iter\".format(fold)):\n",
    "                model = joblib.load(path + fname)\n",
    "                model.save_model(path + 'cp_{}_model.txt'.format(fold))\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {\n",
    "    \n",
    "    0: 0.9,\n",
    "    1: 0.9,\n",
    "    2: 0.9,\n",
    "    3: 0.9,\n",
    "    4: 0.9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    'objective': ['binary'],\n",
    "    'metric': ['amex_metric'],\n",
    "    'boosting': ['dart'],\n",
    "    'seed': [42],\n",
    "    'num_leaves': [31],\n",
    "    'learning_rate': [0.1],\n",
    "    'drop_rate': [0.1],\n",
    "    'feature_fraction': [1.0],\n",
    "    'bagging_freq': [0],\n",
    "    'bagging_fraction': [1.0],\n",
    "    'n_jobs': [-1],\n",
    "    'lambda_l1': [0.0],\n",
    "    'lambda_l2': [0.0],\n",
    "    'min_data_in_leaf': [20]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid  = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "for run, parameters in enumerate(grid):\n",
    "    print('-' * 50)\n",
    "    print(run, len_grid, parameters)\n",
    "    train_and_evaluate(data, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Output/test_DART_folds.csv', index_col='customer_ID')\n",
    "columns = test.columns\n",
    "\n",
    "test['mean'] = test[columns].mean(axis=1)\n",
    "test['std'] = test[columns].std(axis=1)\n",
    "test['min'] = test[columns].min(axis=1)\n",
    "test['max'] = test[columns].max(axis=1)\n",
    "test['median'] = test[columns].median(axis=1)\n",
    "test['skew'] = test[columns].skew(axis=1)\n",
    "test['kurtosis'] = test[columns].kurtosis(axis=1)\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1_iter_194_score_0.99999.pkl\n",
      "fold_4_iter_20_score_1.00000.pkl\n",
      "fold_3_iter_247_score_0.99998.pkl\n",
      "fold_2_iter_248_score_0.99990.pkl\n",
      "fold_0_iter_172_score_0.99988.pkl\n"
     ]
    }
   ],
   "source": [
    "path = 'Ensemble_DART/'\n",
    "pred_list = []\n",
    "for fname in os.listdir(path):\n",
    "    if fname.startswith(\"fold_\"):\n",
    "        print(fname)\n",
    "        model = joblib.load(path + fname)\n",
    "        pred_list.append(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = [\n",
    "    'fold_1',\n",
    "    'fold_4',\n",
    "    'fold_3',\n",
    "    'fold_2',\n",
    "    'fold_0',\n",
    "]\n",
    "\n",
    "pred_df = pd.DataFrame(pred_list).T\n",
    "pred_df.columns = column_name\n",
    "pred_df.index = data.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rapids-22.06')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "468ef23ed2970eb3eae24d512361eed443dbea3050d88b5fbf8075c8ae4b100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
