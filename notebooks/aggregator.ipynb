{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('Data/train_data.pkl')\n",
    "test_data = pd.read_pickle('Data/test_data.pkl')\n",
    "\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_features = []\n",
    "\n",
    "train_data.drop(columns=['S_2'], axis=1, inplace=True)\n",
    "test_data.drop(columns=['S_2'], axis=1, inplace=True)\n",
    "\n",
    "categorical_features = ['B_30', 'B_31', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "numerical_features = list(set(train_data.columns).difference(set(categorical_features)))\n",
    "\n",
    "for i in to_remove_features:\n",
    "    numerical_features.remove(i)\n",
    "\n",
    "len(numerical_features), len(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator(df):\n",
    "    operation_list = []\n",
    "    for i in numerical_features:\n",
    "        operation_list.append(['mean', 'std', 'min', 'max', 'last'])\n",
    "    dic_numerical = dict(zip(numerical_features, operation_list))\n",
    "    df_agg_num = df.groupby('customer_ID').agg(dic_numerical)\n",
    "    df_agg_num.columns = ['_num_'.join(x) for x in df_agg_num.columns]\n",
    "\n",
    "    operation_list = []\n",
    "    for i in categorical_features:\n",
    "        operation_list.append(['count', 'last', 'nunique'])\n",
    "    dic_categorical = dict(zip(categorical_features, operation_list))\n",
    "    df_agg_cat = df.groupby('customer_ID').agg(dic_categorical)\n",
    "    df_agg_cat.columns = ['_cat_'.join(x) for x in df_agg_cat.columns]\n",
    "\n",
    "    df_agg = pd.concat([df_agg_num, df_agg_cat], axis = 1)\n",
    "    return df_agg\n",
    "\n",
    "train_agg = aggregator(train_data)\n",
    "test_agg = aggregator(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg.shape, test_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLY_ONE_HOT_ENC = False\n",
    "if APPLY_ONE_HOT_ENC:\n",
    "    cat_feature_last = train_agg.columns[train_agg.columns.str.contains('_cat_last')]\n",
    "    train_agg[cat_feature_last] = train_agg[cat_feature_last].astype(str)\n",
    "    test_agg[cat_feature_last] = test_agg[cat_feature_last].astype(str)\n",
    "    enc = OneHotEncoder()\n",
    "    train_encoded_df = enc.fit_transform(train_agg[cat_feature_last])\n",
    "    test_encoded_df = enc.transform(test_agg[cat_feature_last])\n",
    "    column_name = []\n",
    "    for i in range(0, train_encoded_df.shape[1], 1):\n",
    "        column_name.append('enc_' + str(i))\n",
    "    train_enc_df = pd.DataFrame(train_encoded_df.toarray(), columns = column_name, index= train_agg.index)\n",
    "\n",
    "    column_name = []\n",
    "    for i in range(0, test_encoded_df.shape[1], 1):\n",
    "        column_name.append('enc_' + str(i))\n",
    "    test_enc_df = pd.DataFrame(test_encoded_df.toarray(), columns = column_name, index= test_agg.index)\n",
    "    train_agg.drop(columns=cat_feature_last, axis=1, inplace=True)\n",
    "    test_agg.drop(columns=cat_feature_last, axis=1, inplace=True)\n",
    "\n",
    "    train_agg = pd.concat([train_agg, train_enc_df], axis=1)\n",
    "    test_agg = pd.concat([test_agg, test_enc_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLY_LABEL_ENC = True\n",
    "if APPLY_LABEL_ENC:\n",
    "    cat_feature_last = train_agg.columns[train_agg.columns.str.contains('_cat_last')]\n",
    "    train_agg[cat_feature_last] = train_agg[cat_feature_last].astype(str)\n",
    "    test_agg[cat_feature_last] = test_agg[cat_feature_last].astype(str)\n",
    "    enc = OrdinalEncoder()\n",
    "    train_encoded_df = enc.fit_transform(train_agg[cat_feature_last])\n",
    "    test_encoded_df = enc.transform(test_agg[cat_feature_last])\n",
    "    column_name = []\n",
    "    for i in range(0, train_encoded_df.shape[1], 1):\n",
    "        column_name.append('enc_' + str(i))\n",
    "    train_enc_df = pd.DataFrame(train_encoded_df, columns = column_name, index= train_agg.index)\n",
    "\n",
    "    column_name = []\n",
    "    for i in range(0, test_encoded_df.shape[1], 1):\n",
    "        column_name.append('enc_' + str(i))\n",
    "    test_enc_df = pd.DataFrame(test_encoded_df, columns = column_name, index= test_agg.index)\n",
    "    train_agg.drop(columns=cat_feature_last, axis=1, inplace=True)\n",
    "    test_agg.drop(columns=cat_feature_last, axis=1, inplace=True)\n",
    "\n",
    "    train_agg = pd.concat([train_agg, train_enc_df], axis=1)\n",
    "    test_agg = pd.concat([test_agg, test_enc_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_agg = pd.concat([train_agg,test_agg], axis = 0)\n",
    "num_feature_agg = train_test_agg.columns[train_agg.columns.str.contains('_num_')]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_test_scaled = scaler.fit_transform(train_test_agg[num_feature_agg].fillna(train_test_agg[num_feature_agg].median()))\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "train_test_scaled_PCA = pca.fit_transform(train_test_scaled)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "column_name = []\n",
    "for i in range(0, train_test_scaled_PCA.shape[1], 1):\n",
    "    column_name.append('PCA_' + str(i))\n",
    "\n",
    "train_test_PCA_df = pd.DataFrame(train_test_scaled_PCA, columns= column_name, index=train_test_agg.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg_mo = pd.concat([train_agg, train_test_PCA_df.loc[train_agg.index]], axis=1)\n",
    "test_agg_mo = pd.concat([test_agg, train_test_PCA_df.loc[test_agg.index]], axis=1)\n",
    "train_agg_mo.shape, test_agg_mo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg_mo.to_pickle('Data/train_agg_mo.pkl')\n",
    "test_agg_mo.to_pickle('Data/test_agg_mo.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
