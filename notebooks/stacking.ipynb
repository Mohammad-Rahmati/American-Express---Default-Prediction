{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metric import *\n",
    "from baseline_model import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_csv('Output/p_baseline_5_train.csv', index_col='customer_ID')\n",
    "p2 = pd.read_csv('Output/p_baseline_6_train_agg.csv', index_col='customer_ID')\n",
    "train_labels = pd.read_pickle('Data/train_labels.pkl').loc[p1.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([p1, p2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 - seed: 0\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[2000]\tvalid_0's binary_logloss: 0.194425\tvalid_0's AMEX: 0.831962\n",
      "Early stopping, best iteration is:\n",
      "[2400]\tvalid_0's binary_logloss: 0.194085\tvalid_0's AMEX: 0.832321\n",
      "Fold: 0 - seed: 0 - score 83.23%\n",
      "Fold: 0 - seed: 1\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1457]\tvalid_0's binary_logloss: 0.193231\tvalid_0's AMEX: 0.832989\n",
      "Fold: 0 - seed: 1 - score 83.30%\n",
      "Fold: 1 - seed: 0\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[2000]\tvalid_0's binary_logloss: 0.194127\tvalid_0's AMEX: 0.828921\n",
      "Early stopping, best iteration is:\n",
      "[2267]\tvalid_0's binary_logloss: 0.193903\tvalid_0's AMEX: 0.829473\n",
      "Fold: 1 - seed: 0 - score 82.95%\n",
      "Fold: 1 - seed: 1\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[2000]\tvalid_0's binary_logloss: 0.192934\tvalid_0's AMEX: 0.831013\n",
      "Early stopping, best iteration is:\n",
      "[1559]\tvalid_0's binary_logloss: 0.192953\tvalid_0's AMEX: 0.831197\n",
      "Fold: 1 - seed: 1 - score 83.12%\n",
      "Fold: 2 - seed: 0\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[2000]\tvalid_0's binary_logloss: 0.193743\tvalid_0's AMEX: 0.827355\n",
      "Early stopping, best iteration is:\n",
      "[2229]\tvalid_0's binary_logloss: 0.193534\tvalid_0's AMEX: 0.827966\n",
      "Fold: 2 - seed: 0 - score 82.80%\n",
      "Fold: 2 - seed: 1\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1248]\tvalid_0's binary_logloss: 0.192794\tvalid_0's AMEX: 0.829219\n",
      "Fold: 2 - seed: 1 - score 82.92%\n",
      "Fold: 3 - seed: 0\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[2000]\tvalid_0's binary_logloss: 0.191028\tvalid_0's AMEX: 0.834256\n",
      "Early stopping, best iteration is:\n",
      "[3050]\tvalid_0's binary_logloss: 0.190403\tvalid_0's AMEX: 0.835199\n",
      "Fold: 3 - seed: 0 - score 83.52%\n",
      "Fold: 3 - seed: 1\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[989]\tvalid_0's binary_logloss: 0.190308\tvalid_0's AMEX: 0.834905\n",
      "Fold: 3 - seed: 1 - score 83.49%\n",
      "Fold: 4 - seed: 0\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[2000]\tvalid_0's binary_logloss: 0.196736\tvalid_0's AMEX: 0.825592\n",
      "Early stopping, best iteration is:\n",
      "[1813]\tvalid_0's binary_logloss: 0.196803\tvalid_0's AMEX: 0.826027\n",
      "Fold: 4 - seed: 0 - score 82.60%\n",
      "Fold: 4 - seed: 1\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1022]\tvalid_0's binary_logloss: 0.196264\tvalid_0's AMEX: 0.826564\n",
      "Fold: 4 - seed: 1 - score 82.66%\n"
     ]
    }
   ],
   "source": [
    "models, df_scores, importances, df_results = base_model_lgbm(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(models, open(\"Models/models_ensemble.pkl\", \"wb\"))\n",
    "pickle.dump(importances, open(\"Models/importances_ensemble.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>seed</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>fold_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.832321</td>\n",
       "      <td>0.832989</td>\n",
       "      <td>0.832655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829473</td>\n",
       "      <td>0.831197</td>\n",
       "      <td>0.830335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827966</td>\n",
       "      <td>0.829219</td>\n",
       "      <td>0.828592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.835199</td>\n",
       "      <td>0.834905</td>\n",
       "      <td>0.835052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.826027</td>\n",
       "      <td>0.826564</td>\n",
       "      <td>0.826295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seed_mean</th>\n",
       "      <td>0.830197</td>\n",
       "      <td>0.830975</td>\n",
       "      <td>0.830586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "seed              0         1  fold_mean\n",
       "fold                                    \n",
       "0          0.832321  0.832989   0.832655\n",
       "1          0.829473  0.831197   0.830335\n",
       "2          0.827966  0.829219   0.828592\n",
       "3          0.835199  0.834905   0.835052\n",
       "4          0.826027  0.826564   0.826295\n",
       "seed_mean  0.830197  0.830975   0.830586"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = pickle.load(open(\"Models/importances_ensemble.pkl\", \"rb\"))\n",
    "def plot_importance(ii, features, PLOT_TOP_N = 50, figsize=(10, 10)):\n",
    "    importance_df = pd.DataFrame(data=importances, columns=features)\n",
    "    sorted_indices = importance_df.median(axis=0).sort_values(ascending=False).index\n",
    "    sorted_importance_df = importance_df.loc[:, sorted_indices]\n",
    "    plot_cols = sorted_importance_df.columns[:PLOT_TOP_N]\n",
    "    _, ax = plt.subplots(figsize=figsize)\n",
    "    ax.grid()\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel('Feature')\n",
    "    ax.set_xlabel('Importance')\n",
    "    sns.boxplot(data=sorted_importance_df[plot_cols],\n",
    "                orient='h',\n",
    "                ax=ax)\n",
    "    plt.show()\n",
    "    \n",
    "plot_importance(np.array(importances),train.columns, PLOT_TOP_N = 50, figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_test = pd.read_csv('Output/p_baseline_5_test.csv', index_col='customer_ID')\n",
    "p2_test = pd.read_csv('Output/p_baseline_6_test_agg.csv', index_col='customer_ID')\n",
    "test = pd.concat([p1_test, p2_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = []\n",
    "for keys in models.keys():\n",
    "    prediction_list.append(models[keys].predict(test))\n",
    "\n",
    "prediction_df = pd.DataFrame(prediction_list).T\n",
    "prediction_df.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.mean(axis=1).to_csv('Output/p_ensemble.csv',header=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7</th>\n",
       "      <td>0.020216</td>\n",
       "      <td>0.025179</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>0.028232</td>\n",
       "      <td>0.021624</td>\n",
       "      <td>0.028360</td>\n",
       "      <td>0.021291</td>\n",
       "      <td>0.029601</td>\n",
       "      <td>0.021768</td>\n",
       "      <td>0.025379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397d4263dafa1daedef5</th>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5e400fc98e7bd43ce8</th>\n",
       "      <td>0.034057</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>0.034630</td>\n",
       "      <td>0.033217</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>0.032984</td>\n",
       "      <td>0.043172</td>\n",
       "      <td>0.036343</td>\n",
       "      <td>0.033173</td>\n",
       "      <td>0.030542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf6e56734528702d694</th>\n",
       "      <td>0.214902</td>\n",
       "      <td>0.211433</td>\n",
       "      <td>0.224476</td>\n",
       "      <td>0.225818</td>\n",
       "      <td>0.229136</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.225142</td>\n",
       "      <td>0.234561</td>\n",
       "      <td>0.221803</td>\n",
       "      <td>0.229291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a4693dd914fca22557</th>\n",
       "      <td>0.882868</td>\n",
       "      <td>0.880309</td>\n",
       "      <td>0.889936</td>\n",
       "      <td>0.874872</td>\n",
       "      <td>0.869313</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.884684</td>\n",
       "      <td>0.878161</td>\n",
       "      <td>0.891358</td>\n",
       "      <td>0.890621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c5d60460dba6dedc41e</th>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.008414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3a4f0ca3de613b0b2ad</th>\n",
       "      <td>0.784557</td>\n",
       "      <td>0.760640</td>\n",
       "      <td>0.768210</td>\n",
       "      <td>0.771154</td>\n",
       "      <td>0.792950</td>\n",
       "      <td>0.773279</td>\n",
       "      <td>0.749139</td>\n",
       "      <td>0.778119</td>\n",
       "      <td>0.785153</td>\n",
       "      <td>0.774365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475cb095d2443a68030f1</th>\n",
       "      <td>0.465095</td>\n",
       "      <td>0.473785</td>\n",
       "      <td>0.436535</td>\n",
       "      <td>0.453781</td>\n",
       "      <td>0.443923</td>\n",
       "      <td>0.442764</td>\n",
       "      <td>0.509489</td>\n",
       "      <td>0.526670</td>\n",
       "      <td>0.500959</td>\n",
       "      <td>0.505120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffddef1fc3643ea179c93245b68dca0f36941cd83977822e8b356988ca4d07</th>\n",
       "      <td>0.219111</td>\n",
       "      <td>0.227781</td>\n",
       "      <td>0.231916</td>\n",
       "      <td>0.229223</td>\n",
       "      <td>0.257621</td>\n",
       "      <td>0.260171</td>\n",
       "      <td>0.267054</td>\n",
       "      <td>0.242506</td>\n",
       "      <td>0.256746</td>\n",
       "      <td>0.251225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61cceb803ea8ec37634d</th>\n",
       "      <td>0.043715</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>0.048095</td>\n",
       "      <td>0.055322</td>\n",
       "      <td>0.051306</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>0.054292</td>\n",
       "      <td>0.052405</td>\n",
       "      <td>0.049395</td>\n",
       "      <td>0.055924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924621 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0         1  \\\n",
       "customer_ID                                                              \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.020216  0.025179   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.000377  0.000236   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.034057  0.030509   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.214902  0.211433   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.882868  0.880309   \n",
       "...                                                      ...       ...   \n",
       "ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c5...  0.006583  0.011675   \n",
       "ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3a...  0.784557  0.760640   \n",
       "ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475c...  0.465095  0.473785   \n",
       "ffffddef1fc3643ea179c93245b68dca0f36941cd839778...  0.219111  0.227781   \n",
       "fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61c...  0.043715  0.052286   \n",
       "\n",
       "                                                           2         3  \\\n",
       "customer_ID                                                              \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.022331  0.028232   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.000160  0.000176   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.034630  0.033217   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.224476  0.225818   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.889936  0.874872   \n",
       "...                                                      ...       ...   \n",
       "ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c5...  0.006537  0.009194   \n",
       "ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3a...  0.768210  0.771154   \n",
       "ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475c...  0.436535  0.453781   \n",
       "ffffddef1fc3643ea179c93245b68dca0f36941cd839778...  0.231916  0.229223   \n",
       "fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61c...  0.048095  0.055322   \n",
       "\n",
       "                                                           4         5  \\\n",
       "customer_ID                                                              \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.021624  0.028360   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.000271  0.000195   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.035283  0.032984   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.229136  0.241121   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.869313  0.862484   \n",
       "...                                                      ...       ...   \n",
       "ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c5...  0.006996  0.010695   \n",
       "ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3a...  0.792950  0.773279   \n",
       "ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475c...  0.443923  0.442764   \n",
       "ffffddef1fc3643ea179c93245b68dca0f36941cd839778...  0.257621  0.260171   \n",
       "fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61c...  0.051306  0.055102   \n",
       "\n",
       "                                                           6         7  \\\n",
       "customer_ID                                                              \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.021291  0.029601   \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.000520  0.000334   \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.043172  0.036343   \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.225142  0.234561   \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.884684  0.878161   \n",
       "...                                                      ...       ...   \n",
       "ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c5...  0.004050  0.007503   \n",
       "ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3a...  0.749139  0.778119   \n",
       "ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475c...  0.509489  0.526670   \n",
       "ffffddef1fc3643ea179c93245b68dca0f36941cd839778...  0.267054  0.242506   \n",
       "fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61c...  0.054292  0.052405   \n",
       "\n",
       "                                                           8         9  \n",
       "customer_ID                                                             \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...  0.021768  0.025379  \n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...  0.000325  0.000269  \n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...  0.033173  0.030542  \n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...  0.221803  0.229291  \n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...  0.891358  0.890621  \n",
       "...                                                      ...       ...  \n",
       "ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c5...  0.007818  0.008414  \n",
       "ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3a...  0.785153  0.774365  \n",
       "ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475c...  0.500959  0.505120  \n",
       "ffffddef1fc3643ea179c93245b68dca0f36941cd839778...  0.256746  0.251225  \n",
       "fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61c...  0.049395  0.055924  \n",
       "\n",
       "[924621 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfe2e9041c24d5f91854bb9ffc35eacf9a6123f8e0fdaf39110ac9ad93cae24d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
