{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from evaluation_metric import lgb_amex_metric\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "main_fold = 3\n",
    "\n",
    "class CFG:\n",
    "    input_dir = 'Data/'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def save_model(fold):\n",
    "    def callback(env):\n",
    "        global max_score\n",
    "        iteration = env.iteration\n",
    "        score = env.evaluation_result_list[0][2]\n",
    "        if iteration % 200 == 0:\n",
    "            print('iteration {}, score= {:.05f}, max_score= {:.05f}'.format(iteration,score, max_score))\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            path = 'Models/'\n",
    "            for fname in os.listdir(path):\n",
    "                if fname.startswith(\"fold_{}_{}\".format(main_fold, fold)):\n",
    "                    os.remove(os.path.join(path, fname))\n",
    "\n",
    "            print('High Score: iteration {}, score={:.05f}'.format(iteration, score))\n",
    "            joblib.dump(env.model, 'Models/fold_{}_{}_iter_{}_score_{:.05f}.pkl'.format(main_fold, fold, iteration, score))\n",
    "\n",
    "    callback.order = 0\n",
    "    return callback\n",
    "\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((367131, 1103), (91782, 1103), (367131,), (91782,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_pickle('Output/x_train_fold_{}.pkl'.format(main_fold))\n",
    "x_val = pd.read_pickle('Output/x_val_fold_{}.pkl'.format(main_fold))\n",
    "y_train = pd.read_pickle('Output/y_train_fold_{}.pkl'.format(main_fold))\n",
    "y_val = pd.read_pickle('Output/y_val_fold_{}.pkl'.format(main_fold))\n",
    "\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91782, 1104)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.concat([x_val, y_val], axis=1)\n",
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(x_train_org, y_train_org, val, parameters):\n",
    "    global max_score\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(val, val[CFG.target])):\n",
    "        max_score = 0.785\n",
    "        print(' ')\n",
    "        features = [col for col in x_train_org.columns if col not in ['target']]\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        x_train, x_val = val[features].iloc[trn_ind], val[features].iloc[val_ind]\n",
    "        y_train, y_val = val[CFG.target].iloc[trn_ind], val[CFG.target].iloc[val_ind]\n",
    "        x_train_new = pd.concat([x_train_org, x_train], axis=0)\n",
    "        y_train_new = pd.concat([y_train_org, y_train], axis=0)\n",
    "       \n",
    "        lgb_train = lgb.Dataset(x_train_new, y_train_new, categorical_feature = cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        del x_train, x_val, y_train, y_val, x_train_new, y_train_new; gc.collect()\n",
    "            \n",
    "        model = lgb.train(\n",
    "            params = parameters,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 15000,\n",
    "            valid_sets = [lgb_valid],\n",
    "            feval = lgb_amex_metric,\n",
    "            callbacks=[save_model(fold)],\n",
    "            )\n",
    "\n",
    "        path = 'Models/'\n",
    "        for fname in os.listdir(path):\n",
    "            if fname.startswith(\"fold_{}_{}\".format(main_fold, fold)):\n",
    "                model = joblib.load('Models/' + fname)\n",
    "                model.save_model('Models/cp_{}_{}_model.txt'.format(main_fold, fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric':'None',\n",
    "    'boosting': 'dart',\n",
    "    'seed': CFG.seed,\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'drop_rate': 0.1,\n",
    "    'feature_fraction': 0.20,\n",
    "    'bagging_freq': 10,\n",
    "    'bagging_fraction': 0.50,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 2,\n",
    "    'min_data_in_leaf': 40\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     'objective': ['binary'],\n",
    "#     'metric': ['amex_metric'],\n",
    "#     'boosting': ['dart'],\n",
    "#     'seed': [42],\n",
    "#     'num_leaves': [25, 50, 100, 250, 500, 1000],\n",
    "#     'learning_rate': [0.01, 0.005],\n",
    "#     'drop_rate': [0.01, 0.025, 0.05, 0.1, 0.2],\n",
    "#     'feature_fraction': [0.20,0.30],\n",
    "#     'bagging_freq': [10],\n",
    "#     'bagging_fraction': [0.50,0.60],\n",
    "#     'n_jobs': [-1],\n",
    "#     'lambda_l2': [2],\n",
    "#     'min_data_in_leaf': [40]\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Training fold 0 with 1103 features...\n",
      "[LightGBM] [Info] Number of positive: 114075, number of negative: 326481\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.960023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 187413\n",
      "[LightGBM] [Info] Number of data points in the train set: 440556, number of used features: 1095\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258934 -> initscore=-1.051516\n",
      "[LightGBM] [Info] Start training from score -1.051516\n",
      "iteration 0, score= 0.70588, max_score= 0.78500\n",
      "iteration 200, score= 0.76140, max_score= 0.78500\n",
      "iteration 400, score= 0.76451, max_score= 0.78500\n",
      "iteration 600, score= 0.76905, max_score= 0.78500\n",
      "iteration 800, score= 0.77080, max_score= 0.78500\n",
      "iteration 1000, score= 0.77459, max_score= 0.78500\n",
      "iteration 1200, score= 0.77561, max_score= 0.78500\n",
      "iteration 1400, score= 0.77930, max_score= 0.78500\n",
      "iteration 1600, score= 0.78238, max_score= 0.78500\n",
      "iteration 1800, score= 0.78300, max_score= 0.78500\n",
      "High Score: iteration 1998, score=0.78522\n",
      "High Score: iteration 1999, score=0.78522\n",
      "iteration 2000, score= 0.78491, max_score= 0.78522\n",
      "High Score: iteration 2071, score=0.78532\n",
      "High Score: iteration 2074, score=0.78532\n",
      "High Score: iteration 2075, score=0.78532\n",
      "High Score: iteration 2083, score=0.78546\n",
      "High Score: iteration 2085, score=0.78556\n",
      "High Score: iteration 2086, score=0.78567\n",
      "High Score: iteration 2090, score=0.78567\n",
      "High Score: iteration 2091, score=0.78589\n",
      "High Score: iteration 2173, score=0.78618\n",
      "High Score: iteration 2177, score=0.78618\n",
      "High Score: iteration 2178, score=0.78629\n",
      "High Score: iteration 2179, score=0.78629\n",
      "High Score: iteration 2180, score=0.78629\n",
      "High Score: iteration 2181, score=0.78629\n",
      "High Score: iteration 2182, score=0.78629\n",
      "High Score: iteration 2183, score=0.78640\n",
      "iteration 2200, score= 0.78558, max_score= 0.78640\n",
      "High Score: iteration 2277, score=0.78650\n",
      "High Score: iteration 2278, score=0.78660\n",
      "High Score: iteration 2279, score=0.78660\n",
      "High Score: iteration 2315, score=0.78676\n",
      "High Score: iteration 2316, score=0.78676\n",
      "High Score: iteration 2382, score=0.78684\n",
      "High Score: iteration 2383, score=0.78705\n",
      "High Score: iteration 2391, score=0.78717\n",
      "High Score: iteration 2392, score=0.78717\n",
      "High Score: iteration 2393, score=0.78717\n",
      "High Score: iteration 2395, score=0.78718\n",
      "High Score: iteration 2396, score=0.78718\n",
      "High Score: iteration 2397, score=0.78718\n",
      "iteration 2400, score= 0.78708, max_score= 0.78718\n",
      "High Score: iteration 2404, score=0.78719\n",
      "High Score: iteration 2417, score=0.78720\n",
      "High Score: iteration 2420, score=0.78720\n",
      "High Score: iteration 2421, score=0.78721\n",
      "High Score: iteration 2422, score=0.78721\n",
      "High Score: iteration 2423, score=0.78721\n",
      "High Score: iteration 2424, score=0.78721\n",
      "High Score: iteration 2438, score=0.78724\n",
      "High Score: iteration 2442, score=0.78724\n",
      "High Score: iteration 2443, score=0.78724\n",
      "High Score: iteration 2444, score=0.78724\n",
      "High Score: iteration 2445, score=0.78724\n",
      "High Score: iteration 2475, score=0.78727\n",
      "High Score: iteration 2476, score=0.78727\n",
      "High Score: iteration 2477, score=0.78727\n",
      "High Score: iteration 2478, score=0.78727\n",
      "High Score: iteration 2480, score=0.78727\n",
      "High Score: iteration 2481, score=0.78727\n",
      "High Score: iteration 2482, score=0.78727\n",
      "High Score: iteration 2484, score=0.78738\n",
      "High Score: iteration 2485, score=0.78738\n",
      "High Score: iteration 2488, score=0.78738\n",
      "High Score: iteration 2490, score=0.78749\n",
      "High Score: iteration 2491, score=0.78749\n",
      "High Score: iteration 2492, score=0.78749\n",
      "High Score: iteration 2499, score=0.78750\n",
      "High Score: iteration 2500, score=0.78750\n",
      "High Score: iteration 2501, score=0.78751\n",
      "High Score: iteration 2502, score=0.78772\n",
      "High Score: iteration 2503, score=0.78782\n",
      "iteration 2600, score= 0.78730, max_score= 0.78782\n",
      "High Score: iteration 2715, score=0.78793\n",
      "High Score: iteration 2716, score=0.78793\n",
      "High Score: iteration 2717, score=0.78793\n",
      "High Score: iteration 2718, score=0.78793\n",
      "High Score: iteration 2719, score=0.78793\n",
      "High Score: iteration 2720, score=0.78804\n",
      "High Score: iteration 2728, score=0.78815\n",
      "High Score: iteration 2766, score=0.78818\n",
      "High Score: iteration 2767, score=0.78819\n",
      "High Score: iteration 2769, score=0.78819\n",
      "High Score: iteration 2770, score=0.78819\n",
      "High Score: iteration 2782, score=0.78820\n",
      "High Score: iteration 2783, score=0.78862\n",
      "High Score: iteration 2785, score=0.78873\n",
      "High Score: iteration 2786, score=0.78873\n",
      "High Score: iteration 2788, score=0.78874\n",
      "High Score: iteration 2789, score=0.78874\n",
      "High Score: iteration 2790, score=0.78874\n",
      "iteration 2800, score= 0.78832, max_score= 0.78874\n",
      "High Score: iteration 2812, score=0.78875\n",
      "High Score: iteration 2814, score=0.78875\n",
      "High Score: iteration 2816, score=0.78886\n",
      "iteration 3000, score= 0.78757, max_score= 0.78886\n",
      "High Score: iteration 3093, score=0.78943\n",
      "High Score: iteration 3094, score=0.78943\n",
      "High Score: iteration 3095, score=0.78943\n",
      "High Score: iteration 3096, score=0.78953\n",
      "High Score: iteration 3100, score=0.78953\n",
      "High Score: iteration 3108, score=0.78996\n",
      "High Score: iteration 3109, score=0.78996\n",
      "High Score: iteration 3110, score=0.78996\n",
      "High Score: iteration 3111, score=0.78996\n",
      "High Score: iteration 3112, score=0.78996\n",
      "High Score: iteration 3113, score=0.78996\n",
      "High Score: iteration 3114, score=0.78996\n",
      "High Score: iteration 3115, score=0.78996\n",
      "High Score: iteration 3125, score=0.78997\n",
      "iteration 3200, score= 0.78969, max_score= 0.78997\n",
      "High Score: iteration 3282, score=0.79007\n",
      "High Score: iteration 3283, score=0.79007\n",
      "High Score: iteration 3284, score=0.79007\n",
      "High Score: iteration 3286, score=0.79007\n",
      "High Score: iteration 3295, score=0.79018\n",
      "High Score: iteration 3296, score=0.79029\n",
      "High Score: iteration 3297, score=0.79029\n",
      "High Score: iteration 3298, score=0.79030\n",
      "High Score: iteration 3299, score=0.79030\n",
      "High Score: iteration 3300, score=0.79040\n",
      "High Score: iteration 3331, score=0.79054\n",
      "High Score: iteration 3335, score=0.79055\n",
      "High Score: iteration 3343, score=0.79066\n",
      "High Score: iteration 3346, score=0.79066\n",
      "High Score: iteration 3347, score=0.79066\n",
      "High Score: iteration 3348, score=0.79066\n",
      "High Score: iteration 3351, score=0.79087\n",
      "High Score: iteration 3353, score=0.79088\n",
      "iteration 3400, score= 0.79056, max_score= 0.79088\n",
      "High Score: iteration 3414, score=0.79089\n",
      "High Score: iteration 3415, score=0.79089\n",
      "High Score: iteration 3460, score=0.79102\n",
      "High Score: iteration 3461, score=0.79102\n",
      "High Score: iteration 3543, score=0.79105\n",
      "High Score: iteration 3544, score=0.79105\n",
      "High Score: iteration 3545, score=0.79106\n",
      "High Score: iteration 3547, score=0.79116\n",
      "High Score: iteration 3548, score=0.79116\n",
      "High Score: iteration 3549, score=0.79116\n",
      "High Score: iteration 3550, score=0.79116\n",
      "High Score: iteration 3551, score=0.79127\n",
      "High Score: iteration 3553, score=0.79127\n",
      "High Score: iteration 3554, score=0.79127\n",
      "High Score: iteration 3555, score=0.79137\n",
      "iteration 3600, score= 0.79086, max_score= 0.79137\n",
      "High Score: iteration 3614, score=0.79140\n",
      "High Score: iteration 3618, score=0.79140\n",
      "High Score: iteration 3623, score=0.79140\n",
      "High Score: iteration 3624, score=0.79182\n",
      "High Score: iteration 3625, score=0.79182\n",
      "High Score: iteration 3627, score=0.79193\n",
      "High Score: iteration 3629, score=0.79193\n",
      "High Score: iteration 3643, score=0.79194\n",
      "High Score: iteration 3659, score=0.79194\n",
      "High Score: iteration 3660, score=0.79215\n",
      "High Score: iteration 3662, score=0.79236\n",
      "High Score: iteration 3678, score=0.79237\n",
      "High Score: iteration 3687, score=0.79238\n",
      "High Score: iteration 3688, score=0.79238\n",
      "High Score: iteration 3689, score=0.79238\n",
      "High Score: iteration 3690, score=0.79238\n",
      "High Score: iteration 3692, score=0.79238\n",
      "iteration 3800, score= 0.79106, max_score= 0.79238\n",
      "iteration 4000, score= 0.79125, max_score= 0.79238\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(x_train, y_train, val, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid  = list(ParameterGrid(params))\n",
    "# len_grid = len(grid)\n",
    "# for run, parameters in enumerate(grid):\n",
    "#     print('-' * 50)\n",
    "#     print(run, len_grid, parameters)\n",
    "#     train_and_evaluate(x_train,y_train, val, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rapids-22.06')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "468ef23ed2970eb3eae24d512361eed443dbea3050d88b5fbf8075c8ae4b100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
