{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from evaluation_metric import lgb_amex_metric\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import lightgbm as lgb\n",
    "\n",
    "class CFG:\n",
    "    input_dir = 'Data/'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "\n",
    "score_dic = {\n",
    "    \n",
    "    0:0.78,\n",
    "    1:0.78,\n",
    "    2:0.78,\n",
    "    3:0.78,\n",
    "    4:0.78,\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def save_model(fold):\n",
    "    def callback(env):\n",
    "        iteration = env.iteration\n",
    "        score = env.evaluation_result_list[0][2]\n",
    "        if iteration % 200 == 0:\n",
    "            print('iteration {}, score= {:.05f}, max_score= {:.05f}'.format(iteration,score, score_dic[fold]))\n",
    "        if score > score_dic[fold]:\n",
    "            score_dic[fold] = score\n",
    "            path = 'models_DART_slope/'\n",
    "            for fname in os.listdir(path):\n",
    "                if fname.startswith(\"fold_{}_iter\".format(fold)):\n",
    "                    os.remove(os.path.join(path, fname))\n",
    "\n",
    "            print('High Score: iteration {}, score={:.05f}'.format(iteration, score))\n",
    "            joblib.dump(env.model, path + 'fold_{}_iter_{}_score_{:.05f}.pkl'.format(fold, iteration, score))\n",
    "\n",
    "    callback.order = 0\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(CFG.input_dir + 'train_all_slopes.parquet')\n",
    "labels = pd.read_pickle('Data/train_labels.pkl').loc[train.index]\n",
    "\n",
    "train['target'] = labels\n",
    "\n",
    "cat_features = [\n",
    "    \n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, parameters):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        \n",
    "        print(' ')\n",
    "\n",
    "        features = [col for col in train.columns if col not in ['target']]\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        del x_train, x_val, y_train, y_val; gc.collect()\n",
    "        \n",
    "        path = 'models_DART_slope/'\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params = parameters,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 15000,\n",
    "            valid_sets = [lgb_valid],\n",
    "            feval = lgb_amex_metric,\n",
    "            callbacks=[save_model(fold)],\n",
    "            # init_model= path + 'cp_{}_model.txt'.format(fold),\n",
    "            )\n",
    "\n",
    "        \n",
    "        for fname in os.listdir(path):\n",
    "            if fname.startswith(\"fold_{}_iter\".format(fold)):\n",
    "                model = joblib.load(path + fname)\n",
    "                model.save_model(path + 'cp_{}_model.txt'.format(fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    'objective': ['binary'],\n",
    "    'metric': ['amex_metric'],\n",
    "    'boosting': ['dart'],\n",
    "    'seed': [42],\n",
    "    'num_leaves': [100],\n",
    "    'learning_rate': [0.01],\n",
    "    'drop_rate': [0.1],\n",
    "    'feature_fraction': [0.30],\n",
    "    'bagging_freq': [10],\n",
    "    'bagging_fraction': [0.25],\n",
    "    'n_jobs': [-1],\n",
    "    'lambda_l2': [2],\n",
    "    'min_data_in_leaf': [40]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "0 1 {'bagging_fraction': 0.25, 'bagging_freq': 10, 'boosting': 'dart', 'drop_rate': 0.1, 'feature_fraction': 0.3, 'lambda_l2': 2, 'learning_rate': 0.01, 'metric': 'amex_metric', 'min_data_in_leaf': 40, 'n_jobs': -1, 'num_leaves': 100, 'objective': 'binary', 'seed': 42}\n",
      " \n",
      "Training fold 0 with 1107 features...\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.135239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 188406\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 1099\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "iteration 0, score= 0.69550, max_score= 0.78000\n",
      "iteration 200, score= 0.76654, max_score= 0.78000\n",
      "iteration 400, score= 0.77170, max_score= 0.78000\n",
      "iteration 600, score= 0.77503, max_score= 0.78000\n",
      "High Score: iteration 764, score=0.78004\n",
      "High Score: iteration 765, score=0.78024\n",
      "High Score: iteration 766, score=0.78025\n",
      "High Score: iteration 767, score=0.78026\n",
      "High Score: iteration 783, score=0.78046\n",
      "High Score: iteration 790, score=0.78046\n",
      "High Score: iteration 792, score=0.78054\n",
      "High Score: iteration 793, score=0.78064\n",
      "High Score: iteration 797, score=0.78065\n",
      "iteration 800, score= 0.78055, max_score= 0.78065\n",
      "High Score: iteration 801, score=0.78070\n",
      "High Score: iteration 802, score=0.78098\n",
      "High Score: iteration 803, score=0.78098\n",
      "High Score: iteration 821, score=0.78104\n",
      "High Score: iteration 822, score=0.78108\n",
      "High Score: iteration 823, score=0.78115\n",
      "High Score: iteration 824, score=0.78138\n",
      "High Score: iteration 826, score=0.78144\n",
      "High Score: iteration 843, score=0.78158\n",
      "High Score: iteration 847, score=0.78178\n",
      "High Score: iteration 849, score=0.78179\n",
      "High Score: iteration 861, score=0.78186\n",
      "High Score: iteration 862, score=0.78187\n",
      "High Score: iteration 863, score=0.78191\n",
      "High Score: iteration 864, score=0.78192\n",
      "High Score: iteration 867, score=0.78221\n",
      "High Score: iteration 870, score=0.78244\n",
      "High Score: iteration 876, score=0.78254\n",
      "High Score: iteration 892, score=0.78256\n",
      "High Score: iteration 893, score=0.78264\n",
      "High Score: iteration 894, score=0.78264\n",
      "High Score: iteration 905, score=0.78267\n",
      "High Score: iteration 911, score=0.78282\n",
      "High Score: iteration 913, score=0.78287\n",
      "High Score: iteration 914, score=0.78289\n",
      "High Score: iteration 923, score=0.78315\n",
      "High Score: iteration 925, score=0.78321\n",
      "High Score: iteration 926, score=0.78322\n",
      "High Score: iteration 931, score=0.78353\n",
      "High Score: iteration 932, score=0.78353\n",
      "High Score: iteration 940, score=0.78357\n",
      "High Score: iteration 941, score=0.78358\n",
      "High Score: iteration 942, score=0.78358\n",
      "High Score: iteration 943, score=0.78359\n",
      "High Score: iteration 953, score=0.78359\n",
      "High Score: iteration 973, score=0.78369\n",
      "High Score: iteration 978, score=0.78396\n",
      "iteration 1000, score= 0.78379, max_score= 0.78396\n",
      "High Score: iteration 1011, score=0.78403\n",
      "High Score: iteration 1012, score=0.78405\n",
      "High Score: iteration 1017, score=0.78413\n",
      "High Score: iteration 1018, score=0.78415\n",
      "High Score: iteration 1022, score=0.78417\n",
      "High Score: iteration 1023, score=0.78420\n",
      "High Score: iteration 1025, score=0.78422\n",
      "High Score: iteration 1027, score=0.78427\n",
      "High Score: iteration 1028, score=0.78433\n",
      "High Score: iteration 1034, score=0.78440\n",
      "High Score: iteration 1039, score=0.78442\n",
      "High Score: iteration 1040, score=0.78468\n",
      "High Score: iteration 1041, score=0.78471\n",
      "High Score: iteration 1043, score=0.78473\n",
      "High Score: iteration 1046, score=0.78487\n",
      "High Score: iteration 1052, score=0.78490\n",
      "High Score: iteration 1053, score=0.78497\n",
      "High Score: iteration 1059, score=0.78506\n",
      "High Score: iteration 1061, score=0.78513\n",
      "High Score: iteration 1062, score=0.78526\n",
      "High Score: iteration 1063, score=0.78533\n",
      "High Score: iteration 1068, score=0.78541\n",
      "High Score: iteration 1076, score=0.78545\n",
      "High Score: iteration 1084, score=0.78545\n",
      "High Score: iteration 1091, score=0.78546\n",
      "High Score: iteration 1102, score=0.78552\n",
      "High Score: iteration 1103, score=0.78552\n",
      "High Score: iteration 1104, score=0.78559\n",
      "High Score: iteration 1105, score=0.78559\n",
      "High Score: iteration 1106, score=0.78559\n",
      "High Score: iteration 1107, score=0.78563\n",
      "High Score: iteration 1108, score=0.78570\n",
      "High Score: iteration 1110, score=0.78596\n",
      "High Score: iteration 1136, score=0.78610\n",
      "High Score: iteration 1161, score=0.78616\n",
      "High Score: iteration 1162, score=0.78617\n",
      "High Score: iteration 1173, score=0.78633\n",
      "High Score: iteration 1184, score=0.78634\n",
      "High Score: iteration 1185, score=0.78638\n",
      "iteration 1200, score= 0.78619, max_score= 0.78638\n",
      "High Score: iteration 1205, score=0.78647\n",
      "High Score: iteration 1210, score=0.78649\n",
      "High Score: iteration 1211, score=0.78649\n",
      "High Score: iteration 1216, score=0.78672\n",
      "High Score: iteration 1217, score=0.78676\n",
      "High Score: iteration 1219, score=0.78676\n",
      "High Score: iteration 1220, score=0.78676\n",
      "High Score: iteration 1234, score=0.78676\n",
      "High Score: iteration 1235, score=0.78677\n",
      "High Score: iteration 1244, score=0.78686\n",
      "High Score: iteration 1258, score=0.78704\n",
      "High Score: iteration 1262, score=0.78705\n",
      "High Score: iteration 1265, score=0.78720\n",
      "High Score: iteration 1272, score=0.78747\n",
      "High Score: iteration 1331, score=0.78753\n",
      "High Score: iteration 1335, score=0.78753\n",
      "High Score: iteration 1338, score=0.78753\n",
      "High Score: iteration 1340, score=0.78756\n",
      "High Score: iteration 1341, score=0.78767\n",
      "High Score: iteration 1344, score=0.78786\n",
      "High Score: iteration 1353, score=0.78790\n",
      "High Score: iteration 1366, score=0.78805\n",
      "High Score: iteration 1372, score=0.78827\n",
      "High Score: iteration 1386, score=0.78829\n",
      "High Score: iteration 1389, score=0.78831\n",
      "High Score: iteration 1390, score=0.78848\n",
      "High Score: iteration 1391, score=0.78848\n",
      "High Score: iteration 1397, score=0.78849\n",
      "High Score: iteration 1398, score=0.78852\n",
      "High Score: iteration 1399, score=0.78856\n",
      "iteration 1400, score= 0.78856, max_score= 0.78856\n",
      "High Score: iteration 1400, score=0.78856\n",
      "High Score: iteration 1401, score=0.78857\n",
      "High Score: iteration 1402, score=0.78857\n",
      "High Score: iteration 1403, score=0.78857\n",
      "High Score: iteration 1404, score=0.78895\n",
      "High Score: iteration 1405, score=0.78895\n",
      "High Score: iteration 1411, score=0.78899\n",
      "High Score: iteration 1412, score=0.78899\n",
      "High Score: iteration 1413, score=0.78901\n",
      "High Score: iteration 1414, score=0.78901\n",
      "High Score: iteration 1415, score=0.78904\n",
      "High Score: iteration 1416, score=0.78904\n",
      "High Score: iteration 1417, score=0.78904\n",
      "High Score: iteration 1418, score=0.78908\n",
      "High Score: iteration 1490, score=0.78909\n",
      "High Score: iteration 1491, score=0.78920\n",
      "High Score: iteration 1492, score=0.78922\n",
      "High Score: iteration 1495, score=0.78935\n",
      "High Score: iteration 1498, score=0.78957\n",
      "High Score: iteration 1499, score=0.78959\n",
      "High Score: iteration 1507, score=0.78972\n",
      "High Score: iteration 1510, score=0.79001\n",
      "High Score: iteration 1511, score=0.79001\n",
      "High Score: iteration 1528, score=0.79012\n",
      "High Score: iteration 1569, score=0.79013\n",
      "High Score: iteration 1571, score=0.79024\n",
      "High Score: iteration 1572, score=0.79028\n",
      "High Score: iteration 1573, score=0.79028\n",
      "High Score: iteration 1580, score=0.79034\n",
      "High Score: iteration 1581, score=0.79034\n",
      "High Score: iteration 1582, score=0.79041\n",
      "High Score: iteration 1584, score=0.79055\n",
      "High Score: iteration 1585, score=0.79059\n",
      "High Score: iteration 1586, score=0.79061\n",
      "High Score: iteration 1587, score=0.79062\n",
      "High Score: iteration 1590, score=0.79062\n",
      "iteration 1600, score= 0.79055, max_score= 0.79062\n",
      "High Score: iteration 1602, score=0.79079\n",
      "High Score: iteration 1627, score=0.79079\n",
      "High Score: iteration 1633, score=0.79080\n",
      "High Score: iteration 1634, score=0.79083\n",
      "High Score: iteration 1656, score=0.79086\n",
      "High Score: iteration 1676, score=0.79092\n",
      "High Score: iteration 1677, score=0.79094\n",
      "High Score: iteration 1685, score=0.79099\n",
      "High Score: iteration 1688, score=0.79108\n",
      "High Score: iteration 1689, score=0.79110\n",
      "High Score: iteration 1690, score=0.79116\n",
      "High Score: iteration 1699, score=0.79141\n",
      "High Score: iteration 1718, score=0.79144\n",
      "High Score: iteration 1719, score=0.79146\n",
      "High Score: iteration 1722, score=0.79147\n",
      "High Score: iteration 1724, score=0.79153\n",
      "High Score: iteration 1725, score=0.79162\n",
      "High Score: iteration 1734, score=0.79171\n",
      "High Score: iteration 1745, score=0.79185\n",
      "High Score: iteration 1746, score=0.79189\n",
      "High Score: iteration 1782, score=0.79201\n",
      "High Score: iteration 1783, score=0.79202\n",
      "High Score: iteration 1794, score=0.79204\n",
      "High Score: iteration 1795, score=0.79204\n",
      "High Score: iteration 1796, score=0.79204\n",
      "High Score: iteration 1797, score=0.79204\n",
      "iteration 1800, score= 0.79175, max_score= 0.79204\n",
      "High Score: iteration 1868, score=0.79207\n",
      "High Score: iteration 1891, score=0.79210\n",
      "High Score: iteration 1892, score=0.79221\n",
      "High Score: iteration 1893, score=0.79225\n",
      "High Score: iteration 1894, score=0.79228\n",
      "High Score: iteration 1917, score=0.79252\n",
      "High Score: iteration 1946, score=0.79257\n",
      "High Score: iteration 1947, score=0.79259\n",
      "High Score: iteration 1949, score=0.79259\n",
      "High Score: iteration 1950, score=0.79259\n",
      "High Score: iteration 1957, score=0.79282\n",
      "High Score: iteration 1958, score=0.79290\n",
      "High Score: iteration 1965, score=0.79303\n",
      "High Score: iteration 1968, score=0.79310\n",
      "High Score: iteration 1973, score=0.79311\n",
      "High Score: iteration 1977, score=0.79316\n",
      "High Score: iteration 1978, score=0.79316\n",
      "High Score: iteration 1994, score=0.79330\n",
      "High Score: iteration 1995, score=0.79335\n",
      "iteration 2000, score= 0.79316, max_score= 0.79335\n",
      "High Score: iteration 2049, score=0.79343\n",
      "High Score: iteration 2050, score=0.79343\n",
      "High Score: iteration 2057, score=0.79346\n",
      "High Score: iteration 2059, score=0.79357\n",
      "High Score: iteration 2060, score=0.79357\n",
      "High Score: iteration 2061, score=0.79357\n",
      "High Score: iteration 2116, score=0.79358\n",
      "High Score: iteration 2137, score=0.79367\n",
      "High Score: iteration 2146, score=0.79368\n",
      "High Score: iteration 2147, score=0.79370\n",
      "High Score: iteration 2149, score=0.79383\n",
      "High Score: iteration 2174, score=0.79398\n",
      "High Score: iteration 2175, score=0.79401\n",
      "High Score: iteration 2185, score=0.79409\n",
      "High Score: iteration 2186, score=0.79409\n",
      "High Score: iteration 2191, score=0.79415\n",
      "High Score: iteration 2193, score=0.79428\n",
      "iteration 2200, score= 0.79396, max_score= 0.79428\n",
      "High Score: iteration 2259, score=0.79435\n",
      "High Score: iteration 2290, score=0.79435\n",
      "High Score: iteration 2291, score=0.79461\n",
      "High Score: iteration 2320, score=0.79467\n",
      "High Score: iteration 2321, score=0.79468\n",
      "High Score: iteration 2322, score=0.79468\n",
      "High Score: iteration 2330, score=0.79469\n",
      "High Score: iteration 2398, score=0.79471\n",
      "iteration 2400, score= 0.79467, max_score= 0.79471\n",
      "High Score: iteration 2435, score=0.79473\n",
      "High Score: iteration 2436, score=0.79475\n",
      "High Score: iteration 2447, score=0.79487\n",
      "High Score: iteration 2448, score=0.79492\n",
      "High Score: iteration 2450, score=0.79521\n",
      "High Score: iteration 2451, score=0.79521\n",
      "High Score: iteration 2460, score=0.79534\n",
      "High Score: iteration 2516, score=0.79539\n",
      "High Score: iteration 2517, score=0.79539\n",
      "High Score: iteration 2518, score=0.79539\n",
      "High Score: iteration 2522, score=0.79540\n",
      "High Score: iteration 2552, score=0.79543\n",
      "High Score: iteration 2553, score=0.79550\n",
      "High Score: iteration 2554, score=0.79550\n",
      "High Score: iteration 2557, score=0.79554\n",
      "High Score: iteration 2559, score=0.79557\n",
      "High Score: iteration 2583, score=0.79558\n",
      "High Score: iteration 2593, score=0.79559\n",
      "High Score: iteration 2594, score=0.79561\n",
      "iteration 2600, score= 0.79537, max_score= 0.79561\n",
      "High Score: iteration 2609, score=0.79565\n",
      "High Score: iteration 2611, score=0.79566\n",
      "High Score: iteration 2614, score=0.79566\n",
      "High Score: iteration 2616, score=0.79566\n",
      "High Score: iteration 2624, score=0.79585\n",
      "High Score: iteration 2626, score=0.79588\n",
      "High Score: iteration 2628, score=0.79598\n",
      "High Score: iteration 2641, score=0.79609\n",
      "High Score: iteration 2642, score=0.79616\n",
      "High Score: iteration 2673, score=0.79627\n",
      "High Score: iteration 2674, score=0.79629\n",
      "High Score: iteration 2675, score=0.79633\n",
      "High Score: iteration 2687, score=0.79633\n",
      "High Score: iteration 2688, score=0.79640\n",
      "High Score: iteration 2719, score=0.79648\n",
      "High Score: iteration 2720, score=0.79650\n",
      "High Score: iteration 2729, score=0.79682\n",
      "iteration 2800, score= 0.79658, max_score= 0.79682\n",
      "High Score: iteration 2915, score=0.79689\n",
      "High Score: iteration 2916, score=0.79691\n",
      "High Score: iteration 2918, score=0.79694\n",
      "High Score: iteration 2921, score=0.79720\n",
      "High Score: iteration 2925, score=0.79735\n",
      "High Score: iteration 2926, score=0.79739\n",
      "High Score: iteration 2927, score=0.79739\n",
      "High Score: iteration 2935, score=0.79747\n",
      "iteration 3000, score= 0.79705, max_score= 0.79747\n",
      "High Score: iteration 3039, score=0.79757\n",
      "High Score: iteration 3040, score=0.79760\n",
      "High Score: iteration 3041, score=0.79760\n",
      "High Score: iteration 3169, score=0.79768\n",
      "High Score: iteration 3172, score=0.79771\n",
      "High Score: iteration 3173, score=0.79771\n",
      "High Score: iteration 3177, score=0.79775\n",
      "High Score: iteration 3187, score=0.79778\n",
      "High Score: iteration 3188, score=0.79791\n",
      "High Score: iteration 3189, score=0.79803\n",
      "iteration 3200, score= 0.79796, max_score= 0.79803\n",
      "High Score: iteration 3201, score=0.79804\n",
      "High Score: iteration 3203, score=0.79804\n",
      "High Score: iteration 3210, score=0.79805\n",
      "High Score: iteration 3213, score=0.79809\n",
      "High Score: iteration 3214, score=0.79809\n",
      "High Score: iteration 3215, score=0.79809\n",
      "High Score: iteration 3223, score=0.79811\n",
      "High Score: iteration 3224, score=0.79830\n",
      "High Score: iteration 3255, score=0.79840\n",
      "High Score: iteration 3256, score=0.79840\n",
      "High Score: iteration 3262, score=0.79841\n",
      "High Score: iteration 3263, score=0.79841\n",
      "High Score: iteration 3264, score=0.79841\n",
      "High Score: iteration 3267, score=0.79841\n",
      "High Score: iteration 3268, score=0.79841\n",
      "High Score: iteration 3269, score=0.79841\n",
      "High Score: iteration 3270, score=0.79842\n",
      "High Score: iteration 3271, score=0.79842\n",
      "High Score: iteration 3278, score=0.79842\n",
      "High Score: iteration 3305, score=0.79859\n",
      "High Score: iteration 3316, score=0.79861\n",
      "High Score: iteration 3333, score=0.79867\n",
      "High Score: iteration 3334, score=0.79867\n",
      "High Score: iteration 3335, score=0.79867\n",
      "High Score: iteration 3343, score=0.79876\n",
      "High Score: iteration 3344, score=0.79880\n",
      "High Score: iteration 3345, score=0.79889\n",
      "High Score: iteration 3346, score=0.79891\n",
      "High Score: iteration 3347, score=0.79891\n",
      "High Score: iteration 3348, score=0.79891\n",
      "High Score: iteration 3349, score=0.79891\n",
      "High Score: iteration 3350, score=0.79891\n",
      "High Score: iteration 3371, score=0.79897\n",
      "iteration 3400, score= 0.79840, max_score= 0.79897\n",
      "High Score: iteration 3547, score=0.79900\n",
      "High Score: iteration 3548, score=0.79900\n",
      "High Score: iteration 3550, score=0.79900\n",
      "High Score: iteration 3551, score=0.79900\n",
      "High Score: iteration 3552, score=0.79902\n",
      "High Score: iteration 3553, score=0.79902\n",
      "High Score: iteration 3554, score=0.79909\n",
      "High Score: iteration 3562, score=0.79914\n",
      "High Score: iteration 3563, score=0.79918\n",
      "High Score: iteration 3564, score=0.79920\n",
      "High Score: iteration 3571, score=0.79924\n",
      "iteration 3600, score= 0.79878, max_score= 0.79924\n",
      "High Score: iteration 3676, score=0.79925\n",
      "High Score: iteration 3696, score=0.79946\n",
      "High Score: iteration 3697, score=0.79946\n",
      "High Score: iteration 3698, score=0.79955\n",
      "iteration 3800, score= 0.79919, max_score= 0.79955\n",
      "iteration 4000, score= 0.79937, max_score= 0.79955\n",
      "High Score: iteration 4087, score=0.79961\n",
      "High Score: iteration 4090, score=0.79972\n",
      "High Score: iteration 4091, score=0.79972\n",
      "High Score: iteration 4098, score=0.79973\n",
      "High Score: iteration 4099, score=0.79973\n",
      "High Score: iteration 4105, score=0.79973\n",
      "High Score: iteration 4111, score=0.79983\n",
      "High Score: iteration 4112, score=0.79983\n",
      "High Score: iteration 4113, score=0.79994\n",
      "High Score: iteration 4114, score=0.79994\n",
      "High Score: iteration 4115, score=0.80003\n",
      "High Score: iteration 4116, score=0.80007\n",
      "High Score: iteration 4117, score=0.80009\n",
      "iteration 4200, score= 0.79930, max_score= 0.80009\n",
      "iteration 4400, score= 0.79918, max_score= 0.80009\n",
      "iteration 4600, score= 0.79849, max_score= 0.80009\n",
      "iteration 4800, score= 0.79937, max_score= 0.80009\n",
      "iteration 5000, score= 0.79897, max_score= 0.80009\n",
      "iteration 5200, score= 0.79906, max_score= 0.80009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m50\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000004?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(run, len_grid, parameters)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000004?line=5'>6</a>\u001b[0m train_and_evaluate(train, parameters)\n",
      "\u001b[1;32m/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb Cell 3'\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(train, parameters)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=13'>14</a>\u001b[0m \u001b[39mdel\u001b[39;00m x_train, x_val, y_train, y_val; gc\u001b[39m.\u001b[39mcollect()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=15'>16</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels_DART_slope/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=17'>18</a>\u001b[0m model \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=18'>19</a>\u001b[0m     params \u001b[39m=\u001b[39;49m parameters,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=19'>20</a>\u001b[0m     train_set \u001b[39m=\u001b[39;49m lgb_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=20'>21</a>\u001b[0m     num_boost_round \u001b[39m=\u001b[39;49m \u001b[39m15000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=21'>22</a>\u001b[0m     valid_sets \u001b[39m=\u001b[39;49m [lgb_valid],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=22'>23</a>\u001b[0m     feval \u001b[39m=\u001b[39;49m lgb_amex_metric,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=23'>24</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[save_model(fold)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=24'>25</a>\u001b[0m     \u001b[39m# init_model= path + 'cp_{}_model.txt'.format(fold),\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=25'>26</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(path):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mora/Desktop/Github/Kaggle/Amex/DART_L1_FE_slope.ipynb#ch0000002?line=29'>30</a>\u001b[0m     \u001b[39mif\u001b[39;00m fname\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mfold_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_iter\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(fold)):\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.06/lib/python3.9/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid  = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "for run, parameters in enumerate(grid):\n",
    "    print('-' * 50)\n",
    "    print(run, len_grid, parameters)\n",
    "    train_and_evaluate(train, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rapids-22.06')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "468ef23ed2970eb3eae24d512361eed443dbea3050d88b5fbf8075c8ae4b100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
