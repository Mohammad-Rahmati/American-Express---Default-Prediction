{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from evaluation_metric import lgb_amex_metric\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import lightgbm as lgb\n",
    "\n",
    "score_dic = {\n",
    "    0: 0.789,\n",
    "    1: 0.789,\n",
    "    2: 0.789,\n",
    "    3: 0.789,\n",
    "    4: 0.789,\n",
    "}\n",
    "\n",
    "class CFG:\n",
    "    input_dir = \"Data/\"\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = \"target\"\n",
    "    path = \"models_DART_all_SEED42/\"\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "def save_model(fold, prefix):\n",
    "    def callback(env):\n",
    "        iteration = env.iteration\n",
    "        score = env.evaluation_result_list[0][2]\n",
    "        if iteration % 500 == 0:\n",
    "            print(\n",
    "                \"iteration {}, score= {:.05f}, max_score= {:.05f}\".format(\n",
    "                    iteration, score, score_dic[fold]\n",
    "                )\n",
    "            )\n",
    "        if score > score_dic[fold]:\n",
    "            score_dic[fold] = score\n",
    "\n",
    "            for fname in os.listdir(CFG.path):\n",
    "                if fname.startswith(\"{}_fold_{}_iter\".format(prefix, fold)):\n",
    "                    os.remove(os.path.join(CFG.path, fname))\n",
    "\n",
    "            print(\"High Score: iteration {}, score={:.05f}\".format(iteration, score))\n",
    "            joblib.dump(\n",
    "                env.model,\n",
    "                CFG.path\n",
    "                + \"{}_fold_{}_iter_{}_score_{:.05f}.pkl\".format(prefix, fold, iteration, score),\n",
    "            )\n",
    "\n",
    "    callback.order = 0\n",
    "    return callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(CFG.input_dir + \"train_all_slopes_corr_pcaslope_lagv2_avediff_catLastLastNAdate.parquet\")\n",
    "labels = pd.read_pickle(\"Data/train_labels.pkl\").loc[train.index]\n",
    "train[\"target\"] = labels\n",
    "\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\",\n",
    "]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "train.shape, labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_col = train.columns[train.columns.str.startswith(\"corr_\")].to_list()\n",
    "\n",
    "top_corr = [\n",
    "    \"corr_D_39-B_26\",\n",
    "    \"corr_D_48-B_4\",\n",
    "    \"corr_P_2-D_44\",\n",
    "    \"corr_D_47-B_4\",\n",
    "    \"corr_D_47-D_39\",\n",
    "    \"corr_P_2-B_4\",\n",
    "    \"corr_D_39-B_10\",\n",
    "    \"corr_D_44-B_4\",\n",
    "    \"corr_D_39-B_2\",\n",
    "    \"corr_D_46-B_4\",\n",
    "    \"corr_D_48-B_3\",\n",
    "    \"corr_D_48-B_9\",\n",
    "    \"corr_S_5-S_24\",\n",
    "    \"corr_S_7-S_3\",\n",
    "    \"corr_D_43-D_144\",\n",
    "    \"corr_D_48-D_39\",\n",
    "    \"corr_P_3-D_46\",\n",
    "    \"corr_S_5-D_43\",\n",
    "    \"corr_R_1-B_4\",\n",
    "    \"corr_P_3-D_47\",\n",
    "    \"corr_D_39-B_3\",\n",
    "    \"corr_R_6-D_39\",\n",
    "    \"corr_S_27-B_2\",\n",
    "    \"corr_S_23-D_43\",\n",
    "    \"corr_R_6-D_69\",\n",
    "    \"corr_P_2-D_48\",\n",
    "    \"corr_S_25-B_4\",\n",
    "    \"corr_D_43-B_4\",\n",
    "    \"corr_R_27-D_69\",\n",
    "    \"corr_S_7-S_27\",\n",
    "    \"corr_D_39-B_11\",\n",
    "    \"corr_S_3-D_39\",\n",
    "    \"corr_S_12-B_4\",\n",
    "    \"corr_D_39-B_15\",\n",
    "    \"corr_R_27-B_26\",\n",
    "    \"corr_S_23-D_39\",\n",
    "    \"corr_R_27-R_1\",\n",
    "    \"corr_R_1-D_39\",\n",
    "    \"corr_S_19-D_39\",\n",
    "    \"corr_S_27-B_3\",\n",
    "    \"corr_S_16-D_39\",\n",
    "    \"corr_R_27-B_5\",\n",
    "    \"corr_S_3-D_62\",\n",
    "    \"corr_D_71-D_62\",\n",
    "    \"corr_R_27-D_39\",\n",
    "    \"corr_D_48-D_43\",\n",
    "    \"corr_D_61-B_36\",\n",
    "    \"corr_S_25-D_39\",\n",
    "    \"corr_R_6-D_43\",\n",
    "    \"corr_S_27-R_27\",\n",
    "    \"corr_S_27-S_12\",\n",
    "    \"corr_S_27-D_39\",\n",
    "    \"corr_D_46-B_3\",\n",
    "    \"corr_D_62-D_47\",\n",
    "    \"corr_B_4-B_3\",\n",
    "    \"corr_R_1-D_48\",\n",
    "]\n",
    "\n",
    "corr_to_remove = set(corr_col).difference(set(top_corr))\n",
    "train.drop(corr_to_remove, axis=1, inplace=True)\n",
    "train.shape, len(top_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, parameters, rounds, folds = [0,1,2,3,4], load_model=False, prefix='HT0'):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        if fold in folds:\n",
    "            print(\" \")\n",
    "\n",
    "            features = [col for col in train.columns if col not in [\"target\"]]\n",
    "            print(f\"Training fold {fold} with {len(features)} features...\")\n",
    "            x_train, x_val = (\n",
    "                train[features].iloc[trn_ind],\n",
    "                train[features].iloc[val_ind],\n",
    "            )\n",
    "            y_train, y_val = (\n",
    "                train[CFG.target].iloc[trn_ind],\n",
    "                train[CFG.target].iloc[val_ind],\n",
    "            )\n",
    "            lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features)\n",
    "            lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features)\n",
    "            del x_train, x_val, y_train, y_val\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "            if load_model:\n",
    "                model = lgb.train(\n",
    "                    params=parameters,\n",
    "                    train_set=lgb_train,\n",
    "                num_boost_round=rounds,\n",
    "                    valid_sets=[lgb_valid],\n",
    "                    feval=lgb_amex_metric,\n",
    "                    callbacks=[save_model(fold, prefix)],\n",
    "                    init_model=CFG.path + \"cp_{}_model.txt\".format(fold),\n",
    "                )\n",
    "            else:\n",
    "                model = lgb.train(\n",
    "                params=parameters,\n",
    "                train_set=lgb_train,\n",
    "                num_boost_round=rounds,\n",
    "                valid_sets=[lgb_valid],\n",
    "                feval=lgb_amex_metric,\n",
    "                callbacks=[save_model(fold, prefix)],\n",
    "            )\n",
    "\n",
    "            for fname in os.listdir(CFG.path):\n",
    "                if fname.startswith(\"{}_fold_{}_iter\".format(prefix,fold)):\n",
    "                    model = joblib.load(CFG.path + fname)\n",
    "                    model.save_model(CFG.path + \"cp_{}_model.txt\".format(fold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dic = {\n",
    "    0: 0.80525,\n",
    "    1: 0.79606,\n",
    "    2: 0.80073,\n",
    "    3: 0.79595,\n",
    "    4: 0.80038,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"objective\": [\"binary\"],\n",
    "    \"metric\": [\"amex_metric\"],\n",
    "    \"boosting\": [\"dart\"],\n",
    "    \"seed\": [42, 52],\n",
    "    \"num_leaves\": [70, 80, 90, 100, 110, 120],\n",
    "    \"learning_rate\": [0.01, 0.005],\n",
    "    \"drop_rate\": [0.1, 0.5, 0.9],\n",
    "    \"feature_fraction\": [0.1, 0.50, 0.80],\n",
    "    \"bagging_freq\": [10],\n",
    "    \"bagging_fraction\": [0.50],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"lambda_l1\": [0],\n",
    "    \"lambda_l2\": [20, 40, 100],\n",
    "    \"min_data_in_leaf\": [100, 200, 300],\n",
    "    'force_col_wise':[True]\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "print(f\"{len_grid} models to train\")\n",
    "\n",
    "for run, parameters in enumerate(grid):\n",
    "    if run in [5,25,75,125,175,225,275,325,375,425,475,525,575,625,675,725,775,825,875,925,975,1025,1075,1125,1175,1225,1275,1325,1375,1425,1475,1525,1575,1625,1675,1725,1775,1825,1875,1925]:\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Training run {run} ...\")\n",
    "        train_and_evaluate(train, parameters, folds = [0,1,2,3,4], rounds=150, load_model=True, prefix = 'HT3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rapids-22.06')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "468ef23ed2970eb3eae24d512361eed443dbea3050d88b5fbf8075c8ae4b100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
