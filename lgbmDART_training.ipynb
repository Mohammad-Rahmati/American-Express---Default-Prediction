{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from evaluation_metric import lgb_amex_metric\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "\n",
    "class CFG:\n",
    "    input_dir = \"Data/\"\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = \"target\"\n",
    "    path = \"Models_DART_all_10corr_5folds/\"\n",
    "\n",
    "score_dic = {i: 0.785 for i in range(CFG.n_folds)}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "def save_model(fold, prefix):\n",
    "    def callback(env):\n",
    "        iteration = env.iteration\n",
    "        score = env.evaluation_result_list[0][2]\n",
    "        if iteration % 500 == 0:\n",
    "            print(\n",
    "                \"iteration {}, score= {:.05f}, max_score= {:.05f}\".format(\n",
    "                    iteration, score, score_dic[fold]\n",
    "                )\n",
    "            )\n",
    "        if score > score_dic[fold]:\n",
    "            score_dic[fold] = score\n",
    "\n",
    "            for fname in os.listdir(CFG.path):\n",
    "                if fname.startswith(\"{}_fold_{}_iter\".format(prefix, fold)):\n",
    "                    os.remove(os.path.join(CFG.path, fname))\n",
    "\n",
    "            print(\"High Score: iteration {}, score={:.05f}\".format(iteration, score))\n",
    "            joblib.dump(\n",
    "                env.model,\n",
    "                CFG.path\n",
    "                + \"{}_fold_{}_iter_{}_score_{:.05f}.pkl\".format(prefix, fold, iteration, score),\n",
    "            )it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(CFG.input_dir + \"train_all_slopes_corr_pcaslope_lagv2_avediff_catLastLastNAdate.parquet\")\n",
    "labels = pd.read_pickle(\"Data/train_labels.pkl\").loc[train.index]\n",
    "train[\"target\"] = labels\n",
    "\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\",\n",
    "]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "train.shape, labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_col = train.columns[train.columns.str.startswith(\"corr_\")].to_list()\n",
    "\n",
    "top_corr = [\n",
    "    \"corr_D_39-B_26\",\n",
    "    \"corr_D_48-B_4\",\n",
    "    \"corr_P_2-D_44\",\n",
    "    \"corr_D_47-B_4\",\n",
    "    \"corr_D_47-D_39\",\n",
    "    \"corr_P_2-B_4\",\n",
    "    \"corr_D_39-B_10\",\n",
    "    \"corr_D_44-B_4\",\n",
    "    \"corr_D_39-B_2\",\n",
    "    \"corr_D_46-B_4\",\n",
    "]\n",
    "\n",
    "corr_to_remove = set(corr_col).difference(set(top_corr))\n",
    "train.drop(corr_to_remove, axis=1, inplace=True)\n",
    "train.shape, len(top_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train.sample(frac=0.05, random_state=CFG.seed)\n",
    "test.to_parquet(CFG.path + \"validation.parquet\")\n",
    "train = train.drop(test.index)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [i for i in range(0,CFG.n_folds,1)]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    \n",
    "    print(\"Saving fold {} lgb dataset ...\".format(fold))\n",
    "\n",
    "    features = [col for col in train.columns if col not in [\"target\"]]\n",
    "    \n",
    "    x_train, x_val = (\n",
    "        train[features].iloc[trn_ind],\n",
    "        train[features].iloc[val_ind],\n",
    "    )\n",
    "    y_train, y_val = (\n",
    "        train[CFG.target].iloc[trn_ind],\n",
    "        train[CFG.target].iloc[val_ind],\n",
    "    )\n",
    "    \n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features)\n",
    "    filehandler = open(CFG.path + 'train_fold_{}.pkl'.format(fold),\"wb\")\n",
    "    pickle.dump(lgb_train,filehandler)\n",
    "    filehandler = open(CFG.path +'valid_fold_{}.pkl'.format(fold),\"wb\")\n",
    "    pickle.dump(lgb_valid,filehandler)\n",
    "    filehandler.close()\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(parameters, rounds, folds = [i for i in range(0,CFG.n_folds,1)], load_model=False, prefix='HT0'):\n",
    "\n",
    "    for fold in folds:\n",
    "        print(\"Training fold {} ...\".format(fold))\n",
    "        lgb_train = pickle.load(open(CFG.path + 'train_fold_{}.pkl'.format(fold),\"rb\"))\n",
    "        lgb_valid = pickle.load(open(CFG.path +'valid_fold_{}.pkl'.format(fold),\"rb\"))\n",
    "\n",
    "        if load_model:\n",
    "            model = lgb.train(\n",
    "                params=parameters,\n",
    "                train_set=lgb_train,\n",
    "            num_boost_round=rounds,\n",
    "                valid_sets=[lgb_valid],\n",
    "                feval=lgb_amex_metric,\n",
    "                callbacks=[save_model(fold, prefix)],\n",
    "                init_model=CFG.path + \"cp_{}_model.txt\".format(fold),\n",
    "            )\n",
    "        else:\n",
    "            model = lgb.train(\n",
    "            params=parameters,\n",
    "            train_set=lgb_train,\n",
    "            num_boost_round=rounds,\n",
    "            valid_sets=[lgb_valid],\n",
    "            feval=lgb_amex_metric,\n",
    "            callbacks=[save_model(fold, prefix)],\n",
    "        )\n",
    "        del lgb_train, lgb_valid; _ = gc.collect()\n",
    "        \n",
    "        for fname in os.listdir(CFG.path):\n",
    "            if fname.startswith(\"{}_fold_{}_iter\".format(prefix,fold)):\n",
    "                model = joblib.load(CFG.path + fname)\n",
    "                model.save_model(CFG.path + \"cp_{}_model.txt\".format(fold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dic = {i: 0.785 for i in range(CFG.n_folds)}\n",
    "\n",
    "params = {\n",
    "    \"objective\": [\"binary\"],\n",
    "    \"metric\": [\"amex_metric\"],\n",
    "    \"boosting\": [\"dart\"],\n",
    "    \"seed\": [42],\n",
    "    \"num_leaves\": [100],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"drop_rate\": [0.1],\n",
    "    \"feature_fraction\": [0.2],\n",
    "    \"bagging_freq\": [10],\n",
    "    \"bagging_fraction\": [0.50],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"lambda_l1\": [0],\n",
    "    \"lambda_l2\": [20],\n",
    "    \"min_data_in_leaf\": [40],\n",
    "    'force_col_wise':[True]\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "print(f\"{len_grid} models to train\")\n",
    "\n",
    "for run, parameters in enumerate(grid):\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Training run {run} ...\")\n",
    "    train_and_evaluate(parameters, folds = [0,1,2,3,4], rounds=10000, load_model=False, prefix = 'HT0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": [\"binary\"],\n",
    "    \"metric\": [\"amex_metric\"],\n",
    "    \"boosting\": [\"dart\"],\n",
    "    \"seed\": [1,2,3,4,5],\n",
    "    \"num_leaves\": [100],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"drop_rate\": [0.1],\n",
    "    \"feature_fraction\": [0.2],\n",
    "    \"bagging_freq\": [10],\n",
    "    \"bagging_fraction\": [0.50],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"lambda_l1\": [0],\n",
    "    \"lambda_l2\": [20],\n",
    "    \"min_data_in_leaf\": [40],\n",
    "    'force_col_wise':[True]\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "print(f\"{len_grid} models to train\")\n",
    "\n",
    "for run, parameters in enumerate(grid):\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Training run {run} ...\")\n",
    "    train_and_evaluate(parameters, folds = [0,1,2,3,4], rounds=1000, load_model=True, prefix = 'HT1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": [\"binary\"],\n",
    "    \"metric\": [\"amex_metric\"],\n",
    "    \"boosting\": [\"dart\"],\n",
    "    \"seed\": [6,7,8,9,10],\n",
    "    \"num_leaves\": [100],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"drop_rate\": [0.1],\n",
    "    \"feature_fraction\": [0.2],\n",
    "    \"bagging_freq\": [10],\n",
    "    \"bagging_fraction\": [0.50],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"lambda_l1\": [0],\n",
    "    \"lambda_l2\": [20],\n",
    "    \"min_data_in_leaf\": [40],\n",
    "    'force_col_wise':[True]\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "print(f\"{len_grid} models to train\")\n",
    "\n",
    "for run, parameters in enumerate(grid):\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Training run {run} ...\")\n",
    "    train_and_evaluate(parameters, folds = [0,1,2,3,4], rounds=1000, load_model=True, prefix = 'HT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": [\"binary\"],\n",
    "    \"metric\": [\"amex_metric\"],\n",
    "    \"boosting\": [\"dart\"],\n",
    "    \"seed\": [11,12,13,14,15],\n",
    "    \"num_leaves\": [100],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"drop_rate\": [0.1],\n",
    "    \"feature_fraction\": [0.2],\n",
    "    \"bagging_freq\": [10],\n",
    "    \"bagging_fraction\": [0.50],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"lambda_l1\": [0],\n",
    "    \"lambda_l2\": [20],\n",
    "    \"min_data_in_leaf\": [40],\n",
    "    'force_col_wise':[True]\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "print(f\"{len_grid} models to train\")\n",
    "\n",
    "for run, parameters in enumerate(grid):\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Training run {run} ...\")\n",
    "    train_and_evaluate(parameters, folds = [0,1,2,3,4], rounds=1000, load_model=True, prefix = 'HT3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": [\"binary\"],\n",
    "    \"metric\": [\"amex_metric\"],\n",
    "    \"boosting\": [\"dart\"],\n",
    "    \"seed\": [16,17,18,19,20],\n",
    "    \"num_leaves\": [100],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"drop_rate\": [0.1],\n",
    "    \"feature_fraction\": [0.2],\n",
    "    \"bagging_freq\": [10],\n",
    "    \"bagging_fraction\": [0.50],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"lambda_l1\": [0],\n",
    "    \"lambda_l2\": [20],\n",
    "    \"min_data_in_leaf\": [40],\n",
    "    'force_col_wise':[True]\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "print(f\"{len_grid} models to train\")\n",
    "\n",
    "for run, parameters in enumerate(grid):\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Training run {run} ...\")\n",
    "    train_and_evaluate(parameters, folds = [0,1,2,3,4], rounds=1000, load_model=True, prefix = 'HT4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rapids-22.06')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "468ef23ed2970eb3eae24d512361eed443dbea3050d88b5fbf8075c8ae4b100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
