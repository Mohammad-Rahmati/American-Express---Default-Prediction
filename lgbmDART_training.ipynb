{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from evaluation_metric import lgb_amex_metric\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    input_dir = \"Data/\"\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = \"target\"\n",
    "    path = \"models_DART_all_corr_pacslope_lag_avediff/\"\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "def save_model(fold):\n",
    "    def callback(env):\n",
    "        iteration = env.iteration\n",
    "        score = env.evaluation_result_list[0][2]\n",
    "        if iteration % 500 == 0:\n",
    "            print(\n",
    "                \"iteration {}, score= {:.05f}, max_score= {:.05f}\".format(\n",
    "                    iteration, score, score_dic[fold]\n",
    "                )\n",
    "            )\n",
    "        if score > score_dic[fold]:\n",
    "            score_dic[fold] = score\n",
    "\n",
    "            for fname in os.listdir(CFG.path):\n",
    "                if fname.startswith(\"fold_{}_iter\".format(fold)):\n",
    "                    os.remove(os.path.join(CFG.path, fname))\n",
    "\n",
    "            print(\"High Score: iteration {}, score={:.05f}\".format(iteration, score))\n",
    "            joblib.dump(\n",
    "                env.model,\n",
    "                CFG.path\n",
    "                + \"fold_{}_iter_{}_score_{:.05f}.pkl\".format(fold, iteration, score),\n",
    "            )\n",
    "\n",
    "    callback.order = 0\n",
    "    return callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 3240), (458913, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_parquet(CFG.input_dir + \"train_all_slopes_corr_pcaslope_lag_avediff.parquet\")\n",
    "labels = pd.read_pickle(\"Data/train_labels.pkl\").loc[train.index]\n",
    "train[\"target\"] = labels\n",
    "\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\",\n",
    "]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "train.shape, labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 2075), 60)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_col = train.columns[train.columns.str.startswith(\"corr_\")].to_list()\n",
    "\n",
    "top_corr = [\n",
    "    \"corr_D_39-B_26\",\n",
    "    \"corr_D_48-B_4\",\n",
    "    \"corr_P_2-D_44\",\n",
    "    \"corr_D_47-B_4\",\n",
    "    \"corr_D_47-D_39\",\n",
    "    \"corr_P_2-B_4\",\n",
    "    \"corr_D_39-B_10\",\n",
    "    \"corr_D_44-B_4\",\n",
    "    \"corr_D_39-B_2\",\n",
    "    \"corr_D_46-B_4\",\n",
    "    \"corr_D_48-B_3\",\n",
    "    \"corr_D_48-B_9\",\n",
    "    \"corr_S_5-S_24\",\n",
    "    \"corr_S_7-S_3\",\n",
    "    \"corr_D_43-D_144\",\n",
    "    \"corr_D_48-D_39\",\n",
    "    \"corr_P_3-D_46\",\n",
    "    \"corr_S_5-D_43\",\n",
    "    \"corr_R_1-B_4\",\n",
    "    \"corr_P_3-D_47\",\n",
    "    \"corr_D_39-B_3\",\n",
    "    \"corr_R_6-D_39\",\n",
    "    \"corr_S_27-B_2\",\n",
    "    \"corr_S_23-D_43\",\n",
    "    \"corr_R_6-D_69\",\n",
    "    \"corr_P_2-D_48\",\n",
    "    \"corr_S_25-B_4\",\n",
    "    \"corr_D_43-B_4\",\n",
    "    \"corr_R_27-D_69\",\n",
    "    \"corr_S_7-S_27\",\n",
    "    \"corr_D_39-B_11\",\n",
    "    \"corr_S_3-D_39\",\n",
    "    \"corr_S_12-B_4\",\n",
    "    \"corr_D_39-B_15\",\n",
    "    \"corr_R_27-B_26\",\n",
    "    \"corr_S_23-D_39\",\n",
    "    \"corr_R_27-R_1\",\n",
    "    \"corr_R_1-D_39\",\n",
    "    \"corr_S_19-D_39\",\n",
    "    \"corr_S_27-B_3\",\n",
    "    \"corr_S_16-D_39\",\n",
    "    \"corr_R_27-B_5\",\n",
    "    \"corr_S_3-D_62\",\n",
    "    \"corr_D_71-D_62\",\n",
    "    \"corr_R_27-D_39\",\n",
    "    \"corr_D_48-D_43\",\n",
    "    \"corr_D_61-B_36\",\n",
    "    \"corr_S_25-D_39\",\n",
    "    \"corr_R_6-D_43\",\n",
    "    \"corr_S_27-R_27\",\n",
    "    \"corr_S_27-S_12\",\n",
    "    \"corr_S_27-D_39\",\n",
    "    \"corr_D_46-B_3\",\n",
    "    \"corr_D_62-D_47\",\n",
    "    \"corr_B_4-B_3\",\n",
    "    \"corr_R_1-D_48\",\n",
    "    \"corr_S_16-D_46\",\n",
    "    \"corr_D_61-D_48\",\n",
    "    \"corr_P_2-D_39\",\n",
    "    \"corr_R_27-B_2\",\n",
    "]\n",
    "\n",
    "corr_to_remove = set(corr_col).difference(set(top_corr))\n",
    "train.drop(corr_to_remove, axis=1, inplace=True)\n",
    "train.shape, len(top_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, parameters, rounds, load_model=False):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        if fold in [0, 1, 2, 3, 4]:\n",
    "            print(\" \")\n",
    "\n",
    "            features = [col for col in train.columns if col not in [\"target\"]]\n",
    "            print(f\"Training fold {fold} with {len(features)} features...\")\n",
    "            x_train, x_val = (\n",
    "                train[features].iloc[trn_ind],\n",
    "                train[features].iloc[val_ind],\n",
    "            )\n",
    "            y_train, y_val = (\n",
    "                train[CFG.target].iloc[trn_ind],\n",
    "                train[CFG.target].iloc[val_ind],\n",
    "            )\n",
    "            lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features)\n",
    "            lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features)\n",
    "            del x_train, x_val, y_train, y_val\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "            if load_model:\n",
    "                model = lgb.train(\n",
    "                    params=parameters,\n",
    "                    train_set=lgb_train,\n",
    "                num_boost_round=rounds,\n",
    "                    valid_sets=[lgb_valid],\n",
    "                    feval=lgb_amex_metric,\n",
    "                    callbacks=[save_model(fold)],\n",
    "                    init_model=CFG.path + \"cp_{}_model.txt\".format(fold),\n",
    "                )\n",
    "            else:\n",
    "                model = lgb.train(\n",
    "                params=parameters,\n",
    "                train_set=lgb_train,\n",
    "                num_boost_round=rounds,\n",
    "                valid_sets=[lgb_valid],\n",
    "                feval=lgb_amex_metric,\n",
    "                callbacks=[save_model(fold)],\n",
    "            )\n",
    "\n",
    "            for fname in os.listdir(CFG.path):\n",
    "                if fname.startswith(\"fold_{}_iter\".format(fold)):\n",
    "                    model = joblib.load(CFG.path + fname)\n",
    "                    model.save_model(CFG.path + \"cp_{}_model.txt\".format(fold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 models to train\n",
      "--------------------------------------------------\n",
      "0 1 {'bagging_fraction': 0.5, 'bagging_freq': 10, 'boosting': 'dart', 'drop_rate': 0.1, 'feature_fraction': 0.2, 'lambda_l1': 0, 'lambda_l2': 20, 'learning_rate': 0.01, 'metric': 'amex_metric', 'min_data_in_leaf': 40, 'n_jobs': -1, 'num_leaves': 100, 'objective': 'binary', 'seed': 42}\n",
      " \n",
      "Training fold 0 with 2074 features...\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.074474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 368871\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 2060\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "iteration 0, score= 0.70976, max_score= 0.78900\n",
      "iteration 500, score= 0.77048, max_score= 0.78900\n",
      "iteration 1000, score= 0.78120, max_score= 0.78900\n",
      "iteration 1500, score= 0.78807, max_score= 0.78900\n",
      "High Score: iteration 1596, score=0.78915\n",
      "High Score: iteration 1614, score=0.78915\n",
      "High Score: iteration 1615, score=0.78918\n",
      "High Score: iteration 1616, score=0.78918\n",
      "High Score: iteration 1617, score=0.78922\n",
      "High Score: iteration 1618, score=0.78922\n",
      "High Score: iteration 1627, score=0.78929\n",
      "High Score: iteration 1628, score=0.78931\n",
      "High Score: iteration 1629, score=0.78931\n",
      "High Score: iteration 1642, score=0.78933\n",
      "High Score: iteration 1643, score=0.78933\n",
      "High Score: iteration 1644, score=0.78942\n",
      "High Score: iteration 1648, score=0.78949\n",
      "High Score: iteration 1658, score=0.78950\n",
      "High Score: iteration 1659, score=0.78952\n",
      "High Score: iteration 1667, score=0.78957\n",
      "High Score: iteration 1668, score=0.78959\n",
      "High Score: iteration 1669, score=0.78972\n",
      "High Score: iteration 1670, score=0.78974\n",
      "High Score: iteration 1671, score=0.78979\n",
      "High Score: iteration 1673, score=0.78981\n",
      "High Score: iteration 1675, score=0.78983\n",
      "High Score: iteration 1686, score=0.79009\n",
      "High Score: iteration 1687, score=0.79024\n",
      "High Score: iteration 1691, score=0.79027\n",
      "High Score: iteration 1692, score=0.79027\n",
      "High Score: iteration 1700, score=0.79037\n",
      "High Score: iteration 1705, score=0.79039\n",
      "High Score: iteration 1706, score=0.79039\n",
      "High Score: iteration 1708, score=0.79042\n",
      "High Score: iteration 1709, score=0.79048\n",
      "High Score: iteration 1710, score=0.79051\n",
      "High Score: iteration 1711, score=0.79051\n",
      "High Score: iteration 1712, score=0.79051\n",
      "High Score: iteration 1713, score=0.79051\n",
      "High Score: iteration 1734, score=0.79054\n",
      "High Score: iteration 1743, score=0.79055\n",
      "High Score: iteration 1747, score=0.79057\n",
      "High Score: iteration 1748, score=0.79068\n",
      "High Score: iteration 1858, score=0.79082\n",
      "High Score: iteration 1863, score=0.79085\n",
      "High Score: iteration 1864, score=0.79085\n",
      "High Score: iteration 1868, score=0.79103\n",
      "High Score: iteration 1886, score=0.79103\n",
      "High Score: iteration 1887, score=0.79105\n",
      "High Score: iteration 1888, score=0.79106\n",
      "High Score: iteration 1932, score=0.79123\n",
      "High Score: iteration 1933, score=0.79125\n",
      "High Score: iteration 1936, score=0.79130\n",
      "High Score: iteration 1951, score=0.79132\n",
      "High Score: iteration 1953, score=0.79135\n",
      "High Score: iteration 1954, score=0.79135\n",
      "High Score: iteration 1955, score=0.79137\n",
      "High Score: iteration 1956, score=0.79154\n",
      "High Score: iteration 1957, score=0.79155\n",
      "High Score: iteration 1966, score=0.79157\n",
      "High Score: iteration 1968, score=0.79170\n",
      "iteration 2000, score= 0.79142, max_score= 0.79170\n",
      "High Score: iteration 2024, score=0.79178\n",
      "High Score: iteration 2026, score=0.79181\n",
      "High Score: iteration 2027, score=0.79198\n",
      "High Score: iteration 2041, score=0.79200\n",
      "High Score: iteration 2043, score=0.79211\n",
      "High Score: iteration 2044, score=0.79212\n",
      "High Score: iteration 2045, score=0.79212\n",
      "High Score: iteration 2046, score=0.79226\n",
      "High Score: iteration 2047, score=0.79227\n",
      "High Score: iteration 2048, score=0.79231\n",
      "High Score: iteration 2049, score=0.79233\n",
      "High Score: iteration 2098, score=0.79234\n",
      "High Score: iteration 2099, score=0.79244\n",
      "High Score: iteration 2100, score=0.79244\n",
      "High Score: iteration 2101, score=0.79244\n",
      "High Score: iteration 2102, score=0.79247\n",
      "High Score: iteration 2103, score=0.79247\n",
      "High Score: iteration 2107, score=0.79252\n",
      "High Score: iteration 2108, score=0.79258\n",
      "High Score: iteration 2109, score=0.79258\n",
      "High Score: iteration 2110, score=0.79262\n",
      "High Score: iteration 2112, score=0.79263\n",
      "High Score: iteration 2113, score=0.79263\n",
      "High Score: iteration 2204, score=0.79276\n",
      "High Score: iteration 2213, score=0.79286\n",
      "High Score: iteration 2232, score=0.79287\n",
      "High Score: iteration 2233, score=0.79289\n",
      "High Score: iteration 2234, score=0.79291\n",
      "High Score: iteration 2236, score=0.79293\n",
      "High Score: iteration 2237, score=0.79293\n",
      "High Score: iteration 2238, score=0.79293\n",
      "High Score: iteration 2239, score=0.79302\n",
      "High Score: iteration 2240, score=0.79308\n",
      "High Score: iteration 2247, score=0.79321\n",
      "High Score: iteration 2298, score=0.79321\n",
      "High Score: iteration 2299, score=0.79323\n",
      "High Score: iteration 2300, score=0.79325\n",
      "High Score: iteration 2301, score=0.79327\n",
      "High Score: iteration 2302, score=0.79327\n",
      "High Score: iteration 2303, score=0.79328\n",
      "High Score: iteration 2307, score=0.79328\n",
      "High Score: iteration 2309, score=0.79330\n",
      "High Score: iteration 2318, score=0.79344\n",
      "High Score: iteration 2319, score=0.79344\n",
      "High Score: iteration 2322, score=0.79347\n",
      "High Score: iteration 2325, score=0.79360\n",
      "High Score: iteration 2334, score=0.79365\n",
      "High Score: iteration 2335, score=0.79365\n",
      "High Score: iteration 2336, score=0.79368\n",
      "High Score: iteration 2342, score=0.79377\n",
      "High Score: iteration 2344, score=0.79392\n",
      "High Score: iteration 2362, score=0.79394\n",
      "High Score: iteration 2363, score=0.79396\n",
      "High Score: iteration 2386, score=0.79399\n",
      "High Score: iteration 2388, score=0.79403\n",
      "High Score: iteration 2391, score=0.79418\n",
      "High Score: iteration 2392, score=0.79420\n",
      "High Score: iteration 2393, score=0.79420\n",
      "High Score: iteration 2415, score=0.79426\n",
      "High Score: iteration 2416, score=0.79433\n",
      "High Score: iteration 2420, score=0.79438\n",
      "High Score: iteration 2421, score=0.79438\n",
      "High Score: iteration 2446, score=0.79438\n",
      "High Score: iteration 2447, score=0.79439\n",
      "High Score: iteration 2449, score=0.79441\n",
      "High Score: iteration 2460, score=0.79446\n",
      "High Score: iteration 2463, score=0.79453\n",
      "High Score: iteration 2464, score=0.79455\n",
      "High Score: iteration 2465, score=0.79455\n",
      "High Score: iteration 2466, score=0.79455\n",
      "High Score: iteration 2467, score=0.79460\n",
      "iteration 2500, score= 0.79449, max_score= 0.79460\n",
      "High Score: iteration 2503, score=0.79462\n",
      "High Score: iteration 2506, score=0.79475\n",
      "High Score: iteration 2522, score=0.79497\n",
      "High Score: iteration 2533, score=0.79501\n",
      "High Score: iteration 2714, score=0.79509\n",
      "High Score: iteration 2717, score=0.79511\n",
      "High Score: iteration 2749, score=0.79516\n",
      "High Score: iteration 2750, score=0.79516\n",
      "High Score: iteration 2768, score=0.79519\n",
      "High Score: iteration 2771, score=0.79524\n",
      "High Score: iteration 2774, score=0.79524\n",
      "High Score: iteration 2820, score=0.79524\n",
      "High Score: iteration 2825, score=0.79525\n",
      "High Score: iteration 2827, score=0.79535\n",
      "High Score: iteration 2828, score=0.79535\n",
      "High Score: iteration 2829, score=0.79540\n",
      "High Score: iteration 2912, score=0.79550\n",
      "High Score: iteration 2913, score=0.79552\n",
      "High Score: iteration 2914, score=0.79559\n",
      "High Score: iteration 2916, score=0.79561\n",
      "High Score: iteration 2918, score=0.79562\n",
      "High Score: iteration 2925, score=0.79565\n",
      "High Score: iteration 2928, score=0.79565\n",
      "High Score: iteration 2929, score=0.79565\n",
      "High Score: iteration 2932, score=0.79567\n",
      "High Score: iteration 2933, score=0.79576\n",
      "High Score: iteration 2934, score=0.79576\n",
      "High Score: iteration 2938, score=0.79576\n",
      "High Score: iteration 2954, score=0.79578\n",
      "High Score: iteration 2955, score=0.79582\n",
      "High Score: iteration 2956, score=0.79584\n",
      "High Score: iteration 2973, score=0.79586\n",
      "High Score: iteration 2974, score=0.79587\n",
      "High Score: iteration 2975, score=0.79587\n",
      "High Score: iteration 2983, score=0.79587\n",
      "High Score: iteration 2985, score=0.79590\n",
      "High Score: iteration 2987, score=0.79590\n",
      "High Score: iteration 2989, score=0.79592\n",
      "High Score: iteration 2996, score=0.79608\n",
      "iteration 3000, score= 0.79606, max_score= 0.79608\n",
      "High Score: iteration 3007, score=0.79625\n",
      "High Score: iteration 3009, score=0.79625\n",
      "High Score: iteration 3021, score=0.79626\n",
      "High Score: iteration 3025, score=0.79641\n",
      "High Score: iteration 3067, score=0.79654\n",
      "High Score: iteration 3068, score=0.79656\n",
      "High Score: iteration 3070, score=0.79658\n",
      "High Score: iteration 3071, score=0.79658\n",
      "High Score: iteration 3072, score=0.79660\n",
      "High Score: iteration 3090, score=0.79671\n",
      "High Score: iteration 3094, score=0.79671\n",
      "High Score: iteration 3095, score=0.79671\n",
      "High Score: iteration 3096, score=0.79676\n",
      "High Score: iteration 3099, score=0.79676\n",
      "High Score: iteration 3100, score=0.79676\n",
      "High Score: iteration 3101, score=0.79676\n",
      "High Score: iteration 3121, score=0.79699\n",
      "High Score: iteration 3132, score=0.79706\n",
      "High Score: iteration 3133, score=0.79706\n",
      "High Score: iteration 3145, score=0.79713\n",
      "High Score: iteration 3146, score=0.79719\n",
      "High Score: iteration 3155, score=0.79722\n",
      "High Score: iteration 3161, score=0.79729\n",
      "High Score: iteration 3163, score=0.79740\n",
      "High Score: iteration 3164, score=0.79744\n",
      "High Score: iteration 3168, score=0.79745\n",
      "High Score: iteration 3180, score=0.79746\n",
      "High Score: iteration 3181, score=0.79746\n",
      "High Score: iteration 3318, score=0.79749\n",
      "High Score: iteration 3319, score=0.79749\n",
      "High Score: iteration 3358, score=0.79749\n",
      "High Score: iteration 3359, score=0.79755\n",
      "High Score: iteration 3360, score=0.79760\n",
      "High Score: iteration 3361, score=0.79762\n",
      "High Score: iteration 3362, score=0.79770\n",
      "High Score: iteration 3363, score=0.79773\n",
      "High Score: iteration 3365, score=0.79773\n",
      "High Score: iteration 3366, score=0.79777\n",
      "High Score: iteration 3368, score=0.79777\n",
      "High Score: iteration 3428, score=0.79781\n",
      "High Score: iteration 3443, score=0.79782\n",
      "High Score: iteration 3499, score=0.79788\n",
      "iteration 3500, score= 0.79782, max_score= 0.79788\n",
      "High Score: iteration 3647, score=0.79802\n",
      "High Score: iteration 3648, score=0.79812\n",
      "High Score: iteration 3651, score=0.79817\n",
      "High Score: iteration 3733, score=0.79823\n",
      "High Score: iteration 3734, score=0.79823\n",
      "High Score: iteration 3740, score=0.79823\n",
      "High Score: iteration 3763, score=0.79828\n",
      "High Score: iteration 3766, score=0.79829\n",
      "High Score: iteration 3770, score=0.79833\n",
      "High Score: iteration 3771, score=0.79836\n",
      "High Score: iteration 3772, score=0.79838\n",
      "High Score: iteration 3830, score=0.79841\n",
      "High Score: iteration 3831, score=0.79849\n",
      "High Score: iteration 3832, score=0.79854\n",
      "High Score: iteration 3833, score=0.79854\n",
      "High Score: iteration 3882, score=0.79854\n",
      "High Score: iteration 3889, score=0.79860\n",
      "High Score: iteration 3897, score=0.79867\n",
      "High Score: iteration 3899, score=0.79873\n",
      "High Score: iteration 3909, score=0.79876\n",
      "High Score: iteration 3910, score=0.79881\n",
      "High Score: iteration 3913, score=0.79881\n",
      "High Score: iteration 3914, score=0.79881\n",
      "High Score: iteration 3915, score=0.79881\n",
      "High Score: iteration 3916, score=0.79881\n",
      "High Score: iteration 3917, score=0.79895\n",
      "High Score: iteration 3934, score=0.79896\n",
      "High Score: iteration 3935, score=0.79906\n",
      "High Score: iteration 3937, score=0.79911\n",
      "High Score: iteration 3939, score=0.79917\n",
      "High Score: iteration 3940, score=0.79917\n",
      "High Score: iteration 3980, score=0.79919\n",
      "High Score: iteration 3982, score=0.79921\n",
      "iteration 4000, score= 0.79892, max_score= 0.79921\n",
      "iteration 4500, score= 0.79872, max_score= 0.79921\n",
      "High Score: iteration 4752, score=0.79924\n",
      "High Score: iteration 4759, score=0.79925\n",
      "High Score: iteration 4799, score=0.79926\n",
      "High Score: iteration 4832, score=0.79929\n",
      "High Score: iteration 4984, score=0.79932\n",
      "High Score: iteration 4985, score=0.79932\n",
      "High Score: iteration 4986, score=0.79943\n",
      "High Score: iteration 4987, score=0.79945\n",
      "High Score: iteration 4988, score=0.79945\n",
      "High Score: iteration 4994, score=0.79945\n",
      "iteration 5000, score= 0.79933, max_score= 0.79945\n",
      "High Score: iteration 5008, score=0.79946\n",
      "High Score: iteration 5013, score=0.79946\n",
      "High Score: iteration 5020, score=0.79946\n",
      "High Score: iteration 5021, score=0.79946\n",
      "High Score: iteration 5023, score=0.79946\n",
      "High Score: iteration 5024, score=0.79946\n",
      "High Score: iteration 5027, score=0.79957\n",
      "High Score: iteration 5061, score=0.79958\n",
      "High Score: iteration 5062, score=0.79958\n",
      "High Score: iteration 5063, score=0.79958\n",
      "High Score: iteration 5067, score=0.79958\n",
      "High Score: iteration 5083, score=0.79959\n",
      "High Score: iteration 5084, score=0.79959\n",
      "High Score: iteration 5085, score=0.79959\n",
      "High Score: iteration 5086, score=0.79961\n",
      "High Score: iteration 5103, score=0.79965\n",
      "High Score: iteration 5122, score=0.79967\n",
      "High Score: iteration 5124, score=0.79976\n",
      "High Score: iteration 5125, score=0.79984\n",
      "High Score: iteration 5311, score=0.79989\n",
      "High Score: iteration 5312, score=0.79989\n",
      "High Score: iteration 5313, score=0.79991\n",
      "High Score: iteration 5314, score=0.79991\n",
      "iteration 5500, score= 0.79966, max_score= 0.79991\n",
      "High Score: iteration 5553, score=0.80000\n",
      "High Score: iteration 5556, score=0.80002\n",
      "High Score: iteration 5557, score=0.80002\n",
      "High Score: iteration 5567, score=0.80013\n",
      "High Score: iteration 5735, score=0.80020\n",
      "High Score: iteration 5736, score=0.80022\n",
      "High Score: iteration 5746, score=0.80027\n",
      "High Score: iteration 5749, score=0.80033\n",
      "High Score: iteration 5750, score=0.80033\n",
      "High Score: iteration 5751, score=0.80033\n",
      "High Score: iteration 5752, score=0.80033\n",
      "High Score: iteration 5753, score=0.80033\n",
      "High Score: iteration 5754, score=0.80033\n",
      "High Score: iteration 5755, score=0.80033\n",
      "High Score: iteration 5757, score=0.80033\n",
      "High Score: iteration 5773, score=0.80033\n",
      "High Score: iteration 5843, score=0.80034\n",
      "High Score: iteration 5844, score=0.80034\n",
      "High Score: iteration 5846, score=0.80034\n",
      "High Score: iteration 5858, score=0.80038\n",
      "High Score: iteration 5859, score=0.80040\n",
      "High Score: iteration 5863, score=0.80059\n",
      "High Score: iteration 5865, score=0.80059\n",
      "High Score: iteration 5876, score=0.80062\n",
      "High Score: iteration 5877, score=0.80062\n",
      "High Score: iteration 5878, score=0.80070\n",
      "High Score: iteration 5879, score=0.80070\n",
      "iteration 6000, score= 0.80000, max_score= 0.80070\n",
      "High Score: iteration 6256, score=0.80072\n",
      "High Score: iteration 6257, score=0.80072\n",
      "High Score: iteration 6260, score=0.80072\n",
      "High Score: iteration 6261, score=0.80080\n",
      "High Score: iteration 6262, score=0.80080\n",
      "High Score: iteration 6263, score=0.80080\n",
      "High Score: iteration 6264, score=0.80080\n",
      "High Score: iteration 6266, score=0.80087\n",
      "High Score: iteration 6295, score=0.80089\n",
      "High Score: iteration 6326, score=0.80094\n",
      "High Score: iteration 6327, score=0.80096\n",
      "High Score: iteration 6332, score=0.80102\n",
      "High Score: iteration 6333, score=0.80102\n",
      "High Score: iteration 6334, score=0.80102\n",
      "High Score: iteration 6340, score=0.80102\n",
      "High Score: iteration 6341, score=0.80105\n",
      "High Score: iteration 6344, score=0.80117\n",
      "High Score: iteration 6347, score=0.80117\n",
      "High Score: iteration 6363, score=0.80118\n",
      "High Score: iteration 6364, score=0.80120\n",
      "High Score: iteration 6410, score=0.80123\n",
      "High Score: iteration 6411, score=0.80123\n",
      "High Score: iteration 6418, score=0.80123\n",
      "High Score: iteration 6419, score=0.80126\n",
      "High Score: iteration 6420, score=0.80126\n",
      "High Score: iteration 6421, score=0.80126\n",
      "High Score: iteration 6422, score=0.80126\n",
      "iteration 6500, score= 0.80110, max_score= 0.80126\n",
      "High Score: iteration 6513, score=0.80128\n",
      "High Score: iteration 6514, score=0.80128\n",
      "High Score: iteration 6536, score=0.80128\n",
      "High Score: iteration 6537, score=0.80128\n",
      "High Score: iteration 6538, score=0.80130\n",
      "High Score: iteration 6572, score=0.80131\n",
      "High Score: iteration 6573, score=0.80137\n",
      "High Score: iteration 6646, score=0.80139\n",
      "High Score: iteration 6654, score=0.80143\n",
      "High Score: iteration 6655, score=0.80147\n",
      "High Score: iteration 6665, score=0.80149\n",
      "High Score: iteration 6784, score=0.80156\n",
      "High Score: iteration 6785, score=0.80156\n",
      "High Score: iteration 6850, score=0.80172\n",
      "iteration 7000, score= 0.80136, max_score= 0.80172\n",
      "High Score: iteration 7339, score=0.80174\n",
      "High Score: iteration 7351, score=0.80179\n",
      "High Score: iteration 7354, score=0.80180\n",
      "High Score: iteration 7355, score=0.80180\n",
      "High Score: iteration 7452, score=0.80181\n",
      "High Score: iteration 7453, score=0.80181\n",
      "High Score: iteration 7454, score=0.80188\n",
      "High Score: iteration 7456, score=0.80192\n",
      "High Score: iteration 7458, score=0.80192\n",
      "iteration 7500, score= 0.80167, max_score= 0.80192\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\": [\"binary\"],\n",
    "    \"metric\": [\"amex_metric\"],\n",
    "    \"boosting\": [\"dart\"],\n",
    "    \"seed\": [42],\n",
    "    \"num_leaves\": [100],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"drop_rate\": [0.1],\n",
    "    \"feature_fraction\": [0.20],\n",
    "    \"bagging_freq\": [10],\n",
    "    \"bagging_fraction\": [0.50],\n",
    "    \"n_jobs\": [-1],\n",
    "    \"lambda_l1\": [0],\n",
    "    \"lambda_l2\": [20],\n",
    "    \"min_data_in_leaf\": [40],\n",
    "}\n",
    "\n",
    "score_dic = {\n",
    "    0: 0.789,\n",
    "    1: 0.789,\n",
    "    2: 0.789,\n",
    "    3: 0.789,\n",
    "    4: 0.789,\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "print(f\"{len_grid} models to train\")\n",
    "\n",
    "for run, parameters in enumerate(grid):\n",
    "    print(\"-\" * 50)\n",
    "    print(run, len_grid, parameters)\n",
    "    train_and_evaluate(train, parameters, rounds=15000, load_model=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    'objective': ['binary'],\n",
    "    'metric': ['amex_metric'],\n",
    "    'boosting': ['dart'],\n",
    "    'seed': [42],\n",
    "    'num_leaves': [100],\n",
    "    'learning_rate': [0.01, 0.005],\n",
    "    'drop_rate': [0.1],\n",
    "    'feature_fraction': [0.50],\n",
    "    'bagging_freq': [10],\n",
    "    'bagging_fraction': [0.80],\n",
    "    'n_jobs': [-1],\n",
    "    'lambda_l1': [0],\n",
    "    'lambda_l2': [20],\n",
    "    'min_data_in_leaf': [100, 200, 300, 400, 500]\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "grid = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "print(f\"{len_grid} models to train\")\n",
    "\n",
    "for run, parameters in enumerate(grid):\n",
    "    print(\"-\" * 50)\n",
    "    print(run, len_grid, parameters)\n",
    "    train_and_evaluate(train, parameters, rounds=3000, load_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    'objective': ['binary'],\n",
    "    'metric': ['amex_metric'],\n",
    "    'boosting': ['dart'],\n",
    "    'seed': [42],\n",
    "    'num_leaves': [100],\n",
    "    'learning_rate': [0.01,0.005],\n",
    "    'drop_rate': [0.1],\n",
    "    'feature_fraction': [0.50],\n",
    "    'bagging_freq': [10],\n",
    "    'bagging_fraction': [0.80],\n",
    "    'n_jobs': [-1],\n",
    "    'lambda_l1': [0, 20, 40],\n",
    "    'lambda_l2': [20, 40, 60],\n",
    "    'min_data_in_leaf': [100]\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "grid = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "print(f\"{len_grid} models to train\")\n",
    "\n",
    "for run, parameters in enumerate(grid):\n",
    "    print(\"-\" * 50)\n",
    "    print(run, len_grid, parameters)\n",
    "    train_and_evaluate(train, parameters, rounds=3000, load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rapids-22.06')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "468ef23ed2970eb3eae24d512361eed443dbea3050d88b5fbf8075c8ae4b100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
