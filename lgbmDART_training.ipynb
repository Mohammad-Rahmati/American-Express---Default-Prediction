{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from evaluation_metric import lgb_amex_metric\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import lightgbm as lgb\n",
    "\n",
    "class CFG:\n",
    "    input_dir = 'Data/'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def save_model(fold):\n",
    "    def callback(env):\n",
    "        iteration = env.iteration\n",
    "        score = env.evaluation_result_list[0][2]\n",
    "        if iteration % 200 == 0:\n",
    "            print('iteration {}, score= {:.05f}, max_score= {:.05f}'.format(iteration,score, score_dic[fold]))\n",
    "        if score > score_dic[fold]:\n",
    "            score_dic[fold] = score\n",
    "            path = 'models_DART_SlopesCorrPCAslope/'\n",
    "            for fname in os.listdir(path):\n",
    "                if fname.startswith(\"fold_{}_iter\".format(fold)):\n",
    "                    os.remove(os.path.join(path, fname))\n",
    "\n",
    "            print('High Score: iteration {}, score={:.05f}'.format(iteration, score))\n",
    "            joblib.dump(env.model, path + 'fold_{}_iter_{}_score_{:.05f}.pkl'.format(fold, iteration, score))\n",
    "\n",
    "    callback.order = 0\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 2508), (458913, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_parquet(CFG.input_dir + 'train_all_slopes_corr_pcaslope.parquet')\n",
    "labels = pd.read_pickle('Data/train_labels.pkl').loc[train.index]\n",
    "train['target'] = labels\n",
    "\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "train.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 1379)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_col = train.columns[train.columns.str.startswith('corr_')].to_list()\n",
    "\n",
    "top_corr = ['corr_D_39-B_26', 'corr_D_48-B_4', 'corr_P_2-D_44',\n",
    "       'corr_D_47-B_4', 'corr_D_47-D_39', 'corr_P_2-B_4',\n",
    "       'corr_D_39-B_10', 'corr_D_44-B_4', 'corr_D_39-B_2',\n",
    "       'corr_D_46-B_4', 'corr_D_48-D_47', 'corr_D_48-B_3',\n",
    "       'corr_D_48-B_9', 'corr_S_5-S_24', 'corr_S_7-S_3',\n",
    "       'corr_D_43-D_144', 'corr_D_48-D_39', 'corr_D_44-B_3',\n",
    "       'corr_P_3-D_46', 'corr_S_5-D_43', 'corr_R_1-B_4',\n",
    "       'corr_P_3-D_47', 'corr_D_39-B_3', 'corr_R_6-D_39', 'corr_S_27-B_2',\n",
    "       'corr_S_23-D_43', 'corr_R_6-D_69', 'corr_P_2-D_48',\n",
    "       'corr_S_25-B_4', 'corr_D_43-B_4', 'corr_R_27-D_69',\n",
    "       'corr_S_7-S_27', 'corr_D_39-B_11', 'corr_S_3-D_39',\n",
    "       'corr_S_12-B_4', 'corr_D_39-B_15',\n",
    "       'corr_R_27-B_26', 'corr_S_23-D_39', 'corr_R_27-R_1',\n",
    "       'corr_R_1-D_39', 'corr_S_19-D_39', 'corr_S_27-B_3',\n",
    "       'corr_S_16-D_39', 'corr_R_27-B_5',\n",
    "       'corr_S_3-D_62', 'corr_D_71-D_62', 'corr_R_27-D_39',\n",
    "       'corr_D_48-D_43', 'corr_D_61-B_36', 'corr_D_39-B_4',\n",
    "       'corr_S_25-D_39', 'corr_R_6-D_43', 'corr_S_27-R_27',\n",
    "       'corr_S_27-S_12', 'corr_S_27-D_39', 'corr_D_46-B_3',\n",
    "       'corr_D_62-D_47', 'corr_B_4-B_3', 'corr_R_1-D_48',\n",
    "       'corr_S_16-D_46', 'corr_D_61-D_48', 'corr_P_2-D_39',\n",
    "       'corr_R_27-B_2', 'corr_D_52-D_39', 'corr_S_26-D_62',\n",
    "       'corr_D_44-B_9', 'corr_S_23-R_27', 'corr_D_69-B_24',\n",
    "       'corr_R_27-D_62', 'corr_S_19-R_27', \n",
    "       'corr_R_27-B_21', 'corr_D_52-B_4', 'corr_B_4-B_15',\n",
    "       'corr_D_47-B_3', 'corr_D_43-B_3', 'corr_R_27-D_71',\n",
    "       'corr_D_62-D_144', 'corr_D_39-B_5', 'corr_D_48-D_44',\n",
    "       'corr_S_26-D_43', 'corr_S_5-D_48', 'corr_S_26-D_39',\n",
    "       'corr_P_2-D_61', 'corr_S_27-S_22', 'corr_S_25-D_46',\n",
    "       'corr_S_17-B_4', 'corr_R_27-B_36', 'corr_R_27-B_24',\n",
    "       'corr_D_62-D_52', 'corr_S_12-R_27', 'corr_D_62-B_26',\n",
    "       'corr_S_16-D_62', 'corr_D_62-B_15', 'corr_S_27-D_69',\n",
    "       'corr_R_27-B_9', 'corr_D_43-B_5']\n",
    "\n",
    "corr_to_remove = set(corr_col).difference(set(top_corr))\n",
    "\n",
    "train.drop(corr_to_remove, axis=1, inplace=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, parameters):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        \n",
    "        print(' ')\n",
    "\n",
    "        features = [col for col in train.columns if col not in ['target']]\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        del x_train, x_val, y_train, y_val; gc.collect()\n",
    "        \n",
    "        path = 'models_DART_SlopesCorrPCAslope/'\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params = parameters,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 12000,\n",
    "            valid_sets = [lgb_valid],\n",
    "            feval = lgb_amex_metric,\n",
    "            callbacks=[save_model(fold)],\n",
    "            # init_model= path + 'cp_{}_model.txt'.format(fold),\n",
    "            )\n",
    "        \n",
    "        for fname in os.listdir(path):\n",
    "            if fname.startswith(\"fold_{}_iter\".format(fold)):\n",
    "                model = joblib.load(path + fname)\n",
    "                model.save_model(path + 'cp_{}_model.txt'.format(fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    'objective': ['binary'],\n",
    "    'metric': ['amex_metric'],\n",
    "    'boosting': ['dart'],\n",
    "    'seed': [42],\n",
    "    'num_leaves': [100],\n",
    "    'learning_rate': [0.01],\n",
    "    'drop_rate': [0.1],\n",
    "    'feature_fraction': [0.20],\n",
    "    'bagging_freq': [10],\n",
    "    'bagging_fraction': [0.50],\n",
    "    'n_jobs': [-1],\n",
    "    'lambda_l1': [0],\n",
    "    'lambda_l2': [20],\n",
    "    'min_data_in_leaf': [40]\n",
    "\n",
    "}\n",
    "\n",
    "score_dic = {\n",
    "    \n",
    "    0:0.785,\n",
    "    1:0.785,\n",
    "    2:0.785,\n",
    "    3:0.785,\n",
    "    4:0.785,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "1 1 {'bagging_fraction': 0.5, 'bagging_freq': 10, 'boosting': 'dart', 'drop_rate': 0.1, 'feature_fraction': 0.2, 'lambda_l1': 0, 'lambda_l2': 20, 'learning_rate': 0.01, 'metric': 'amex_metric', 'min_data_in_leaf': 40, 'n_jobs': -1, 'num_leaves': 100, 'objective': 'binary', 'seed': 42}\n",
      " \n",
      "Training fold 0 with 1378 features...\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.260785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 256275\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 1369\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "iteration 0, score= 0.70240, max_score= 0.78500\n",
      "iteration 200, score= 0.76289, max_score= 0.78500\n",
      "iteration 400, score= 0.76718, max_score= 0.78500\n",
      "iteration 600, score= 0.77131, max_score= 0.78500\n",
      "iteration 800, score= 0.77657, max_score= 0.78500\n"
     ]
    }
   ],
   "source": [
    "grid  = list(ParameterGrid(params))\n",
    "len_grid = len(grid)\n",
    "for run, parameters in enumerate(grid):\n",
    "    \n",
    "    print('-' * 50)\n",
    "    print(run+1, len_grid, parameters)\n",
    "    train_and_evaluate(train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rapids-22.06')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "468ef23ed2970eb3eae24d512361eed443dbea3050d88b5fbf8075c8ae4b100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
